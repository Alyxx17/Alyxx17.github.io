---
title: 卡尔曼滤波基本原理
date: 2026-02-16 20:00:00 +0800
categories: [控制,算法]
tags: [控制]
math: true  # <-- 就是这一行，启用本页的数学公式渲染
---

## 序  

2026年的2月16日，除夕晚上，你在家一边看5050直播，一边打死锁(Deadlock),并且假设你正在绿线(Greenwich)对线。突然蓝线(Broadway)的队友发信号：HAZE is missing。你问他HAZE去哪了，他回答：可能去绿线了。你看了眼游戏时间：4分50秒，而在第5分钟会在桥上刷BUFF，所以你推测HAZE可能仅仅是去拿BUFF。那么此刻你就要做出抉择：队友（测量）和自己（预测）到底该相信谁？

假设你是罗伯特·B·程布唐，证人席上，那个你笃定就是犯人的男人，正滔滔不绝地抛出滴水不漏的不在场证明。每一句话都在印证他“无辜者”的身份，与你脑中的推理形成剧烈冲突。你闭上眼睛，脑子里飞速运转：“如果相信我的推理，他现在就该在法庭上认罪；如果相信他的说辞，那之前的线索全都要推翻。”两种信息，落差巨大。你攥紧拳头，知道自己必须在两者之间做出选择——但选择本身不是重点，重点是你得搞清楚：这个巨大的落差，到底是因为他太会伪装（测量误差大），还是因为你从一开始就想错了方向（模型错误）？这就是接下来要聊的话题：当预测和现实剧烈冲突时，该怎么判断，该信谁？  到底要不要喊出：一斤鸭梨！

一个是游戏里的两难，一个是法庭上的对峙。但它们问的是同一个问题：

当两个声音同时在耳边响起，你听谁的？

如果必须二选一，那就成了赌博。但如果可以两个都听呢？只是有的人说话大声点，有的人小声点，你综合一下，得出自己的判断。

这个思路，听起来像不像一种“中庸之道”？

1960年，一个叫鲁道夫·卡尔曼的人把这个想法写成了公式。后来，它成了控制理论和信号处理里绕不开的名字——

卡尔曼滤波。

## 预备知识

### 矩阵  

矩阵的基本概念，运算，转置，逆等。  

### 期望  

在概率论和统计学中，一个离散性随机变量的期望是试验中每次可能的结果乘以其结果概率的总和。例如，掷一枚公平的六面骰子，其每次“点数”的期望是3.5，计算如下：

$$
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
= \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
$$

如果$X$是连续的随机变量，存在一个相应的概率密度函数$f(x)$，若积分$\int\limits_{-∞}^{∞} xf(x)dx$绝对收敛，那么$X$的期望可以计算为：  

$$
E(X)=\int\limits_{-∞}^{∞} xf(x)dx
$$

是针对于连续的随机变量的，与离散随机变量的期望的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。

期望$E$是线性函数，即:$E(aX+bY)=aE(X)+bE(Y)$  

### 方差   

方差是刻画随机变量在其中心位置附近散布程度的数学特征，反映了随机变量取值的离散程度。方差提供了衡量数据在平均值附近波动程度的方法：方差越大，数据分布越分散，波动越大；方差越小，数据越集中，波动越小。为了消除偏差带来的正负抵消，方差对偏离均值的差值进行平方后取期望。方差的常用符号有：$σ^2，s^2，Var(X)，D(X)$。方差的计算公式如下：

$$
Var(x)=E[(X-\mu )^2]
$$

其中$\mu=E(X)$。


### 协方差  

在概率论与统计学中，协方差（Covariance）用于衡量随机变量间的相关程度。  

设$X$和$Y$为两个实值随机变量，它们的协方差定义为它们偏离各自期望值的乘积的期望值，即：  

$$
Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
$$

可以看出协方差的形式类似于方差，只是把其中的一个随机变量$X$换成了$Y$。

通过利用期望的线性性质，协方差的计算公式可以简化为：  

$$
\begin{aligned}
Cov(X, Y) &= E[(X - E[X])(Y - E[Y])] \\
&= E[XY - XE[Y] - E[X]Y + E[X]E[Y]] \\
&= E[XY] - E[X]E[Y] - E[X]E[Y] + E[X]E[Y] \\
&= E[XY] - E[X]E[Y]
\end{aligned}
$$

当协方差为正值时，表明随机变量X和Y倾向于同时偏离其平均值，呈正相关关系；反之，若协方差为负值，则表明一个变量高于平均值时，另一个倾向于低于平均值，呈负相关关系。如果协方差为零，这意味着两个变量之间没有线性关系。

若随机变量$X$与$Y$是相互独立的，那么$Cov(X, Y)=0$。反之，如果两个变量的协方差为$0$（即不相关），不能推出它们相互独立。 




### 递推最小二乘法

## 卡尔曼滤波

## 相关代码

## 常见问题

### 卡尔曼滤波与一般观测器的区别与联系

### 卡尔曼滤波与最小二乘法的区别与联系

## 参考   

最优状态估计:卡尔曼,H及非线性滤波(美)西蒙(Simon,D.)著;张勇刚,李宁,奔粤阳译.一北京:国防工业出版社,2013.5 ISBN 978-7-118-08808-3

---
title: 卡尔曼滤波基本原理
date: 2026-02-16 20:00:00 +0800
categories: [控制,算法]
tags: [控制]
math: true  # <-- 就是这一行，启用本页的数学公式渲染
---

## 序  

> That's one small step for man, one giant leap for mankind. ——Neil Alden Armstrong


![](assets/img/study/Aldrin_Apollo_11_original.webp)

1969年7月20日，阿姆斯特朗踏上月球，说出了这句传世之言。

全世界都听到了这句话。但很少有人知道，在他踏出这一步的瞬间，有一双看不见的手，正在默默计算着他的位置。

那不是人的手。

是卡尔曼滤波(Kalman Filter)。  

登月舱从月球轨道下降到地表，整个过程需要实时知道两件事：我在哪，我要去哪。

但测量是不准的——雷达有噪声，惯性测量单元有漂移。如果只信传感器，会偏；如果只信数学模型，也会偏。

卡尔曼滤波做的事，就是把这两个不太靠谱的信息来源捏在一起，捏出一个足够靠谱的答案。

它不是什么神秘的黑魔法。它是一套数学公式，写成了代码，烧进了阿波罗制导计算机的只读内存里。

这是那段代码的部分：  

![](assets/img/study/code.webp)

这段代码写在人类登月前。它用AGC汇编语言写成，运行在只有2K内存的计算机上，以今天的标准看简陋得不可思议。

但它管用。

它把阿姆斯特朗送到了静海，又把他带回了家。



## 预备知识

### 矩阵  

矩阵的基本概念，运算规则等。  

### 期望  

在概率论和统计学中，一个离散性随机变量的期望是试验中每次可能的结果乘以其结果概率的总和。例如，掷一枚公平的六面骰子，其每次“点数”的期望是$3.5$，计算如下：

$$
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
= \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
$$

如果$X$是连续的随机变量，存在一个相应的概率密度函数$f(x)$，若积分$\int\limits_{-∞}^{∞} xf(x)dx$绝对收敛，那么$X$的期望可以计算为：  

$$
E(X)=\int\limits_{-∞}^{∞} xf(x)dx
$$

是针对于连续的随机变量的，与离散随机变量的期望的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。

期望$E$是线性函数，即:$E(aX+bY)=aE(X)+bE(Y)$  

期望也可表示为：$\bar X$。

### 方差   

方差是刻画随机变量在其中心位置附近散布程度的数学特征，反映了随机变量取值的离散程度。方差提供了衡量数据在平均值附近波动程度的方法：方差越大，数据分布越分散，波动越大；方差越小，数据越集中，波动越小。为了消除偏差带来的正负抵消，方差对偏离均值的差值进行平方后取期望。方差的常用符号有：$σ^2，s^2，Var(X)，D(X)$。方差的计算公式如下：

$$
Var(x)=E[(X-\mu )^2]
$$

其中$\mu=E(X)$。


### 协方差矩阵

在概率论与统计学中，协方差（Covariance）用于衡量随机变量间的相关程度。  

设$X$和$Y$为两个实值随机变量，它们的协方差定义为它们偏离各自期望值的乘积的期望值，即：  

$$
Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
$$

可以看出协方差的形式类似于方差，只是把其中的一个随机变量$X$换成了$Y$。

通过利用期望的线性性质，协方差的计算公式可以简化为：  

$$
\begin{aligned}
Cov(X, Y) &= E[(X - E[X])(Y - E[Y])] \\
&= E[XY - XE[Y] - E[X]Y + E[X]E[Y]] \\
&= E[XY] - E[X]E[Y] - E[X]E[Y] + E[X]E[Y] \\
&= E[XY] - E[X]E[Y]
\end{aligned}
$$

当协方差为正值时，表明随机变量X和Y倾向于同时偏离其平均值，呈正相关关系；反之，若协方差为负值，则表明一个变量高于平均值时，另一个倾向于低于平均值，呈负相关关系。如果协方差为零，这意味着两个变量之间没有线性关系。

若随机变量$X$与$Y$是相互独立的，那么$Cov(X, Y)=0$。反之，如果两个变量的协方差为$0$（即不相关），不能推出它们相互独立。  

下图表明了协方差的意义

![协方差的意义](assets/img/study/Covariance_trends.webp)  

这个可以推广到随机变量是向量的情况。在这种情况下,之前定义的标量变成向量和矩阵。已知一个$n$维的随机变量$X$和一个$m$维的随机变量$Y$(假设$X$和$Y$都是列向量),它们的互相关矩阵定义为：  

$$
R_{XY} = E(XY^T) =
\begin{bmatrix}
E(X_1 Y_1) & \cdots & E(X_1 Y_m) \\
\vdots & \ddots & \vdots \\
E(X_n Y_1) & \cdots & E(X_n Y_m)
\end{bmatrix}
$$
 
协方差矩阵定义为:   

$$
C_{XY} = E[(X - \overline{X})(Y - \overline{Y})^T] = E(XY^T) - \overline{X}·\overline{Y}^T
$$

自协方差矩阵都是对称矩阵，互协方差矩阵不一定对称，甚至不是方阵。

这个$n$维的随机变量的自相关矩阵定义为:  

$$
R_X = E[XX^T] =
\begin{bmatrix}
E[X_1^2] & \cdots & E[X_1 X_n] \\
\vdots & \ddots & \vdots \\
E[X_n X_1] & \cdots & E[X_n^2]
\end{bmatrix}
$$

为了更好的理解协方差矩阵，接下来举一个例子。假设如下数据：  

| 类型   | 概率 $p$ | $X₁$ (学习时长) | $X₂$ (作业完成率) | $Y₁$ (数学) | $Y₂$ (语文) |
| :----- | :----- | :------------ | :-------------- | :-------- | :-------- |
| 学霸   | 0.2    | 12            | 1.0 (100%)      | 95        | 90        |
| 普通生 | 0.5    | 8             | 0.8 (80%)       | 75        | 70        |
| 学困生 | 0.3    | 4             | 0.5 (50%)       | 55        | 50        |

**步骤1：计算每类的 $XY^T$（外积）**

学霸：

$$
XY^T = \begin{bmatrix} 12 \\ 1.0 \end{bmatrix} \begin{bmatrix} 95 & 90 \end{bmatrix} = \begin{bmatrix} 1140 & 1080 \\95 & 90 \end{bmatrix}
$$

普通生：

$$
XY^T = \begin{bmatrix} 8 \\ 0.8 \end{bmatrix} \begin{bmatrix} 75 & 70 \end{bmatrix} = \begin{bmatrix} 600 & 560 \\ 60 & 56 \end{bmatrix}
$$

学困生：

$$
XY^T = \begin{bmatrix} 4 \\ 0.5 \end{bmatrix} \begin{bmatrix} 55 & 50 \end{bmatrix} = \begin{bmatrix} 220 & 200 \\ 27.5 & 25 \end{bmatrix}
$$

**步骤2：计算 $E(XY^T)$（加权平均）**

$$
E(XY^T) = 0.2 \times \begin{bmatrix} 1140 & 1080 \\ 95 & 90 \end{bmatrix} + 0.5 \times \begin{bmatrix} 600 & 560 \\ 60 & 56 \end{bmatrix} + 0.3 \times \begin{bmatrix} 220 & 200 \\ 27.5 & 25 \end{bmatrix}
$$

逐元素计算：

$E(X_1 Y_1) = 0.2 \times 1140 + 0.5 \times 600 + 0.3 \times 220 = 594$

$E(X_1 Y_2) = 0.2 \times 1080 + 0.5 \times 560 + 0.3 \times 200 = 556$

$E(X_2 Y_1) = 0.2 \times 95 + 0.5 \times 60 + 0.3 \times 27.5 = 57.25$

$E(X_2 Y_2) = 0.2 \times 90 + 0.5 \times 56 + 0.3 \times 25 = 53.5$

所以：

$$
R_{XY} = E(XY^T) = \begin{bmatrix} 594 & 556 \\ 57.25 & 53.5 \end{bmatrix}
$$

**步骤3：计算各自的期望 $E(X)$ 和 $E(Y)$** 

$$
E(X) = \begin{bmatrix} E(X_1) \\ E(X_2) \end{bmatrix} = \begin{bmatrix} 0.2 \times 12 + 0.5 \times 8 + 0.3 \times 4 \\ 0.2 \times 1.0 + 0.5 \times 0.8 + 0.3 \times 0.5 \end{bmatrix} = \begin{bmatrix} 7.6 \\ 0.75 \end{bmatrix}
$$

$$
E(Y) = \begin{bmatrix} E(Y_1) \\ E(Y_2) \end{bmatrix} = \begin{bmatrix} 0.2 \times 95 + 0.5 \times 75 + 0.3 \times 55 \\ 0.2 \times 90 + 0.5 \times 70 + 0.3 \times 50 \end{bmatrix} = \begin{bmatrix} 73 \\ 68 \end{bmatrix}
$$

**步骤4：计算 $E(X)E(Y)^T$**

$$
E(X)E(Y)^T = \begin{bmatrix} 7.6 \\ 0.75 \end{bmatrix} \begin{bmatrix} 73 & 68 \end{bmatrix} = \begin{bmatrix} 7.6 \times 73 & 7.6 \times 68 \\ 0.75 \times 73 & 0.75 \times 68 \end{bmatrix} = \begin{bmatrix} 554.8 & 516.8 \\ 54.75 & 51 \end{bmatrix}
$$

**步骤5：计算协方差矩阵 $C_{XY}$**

$$
C_{XY} = E(XY^T) - E(X)E(Y)^T = \begin{bmatrix} 594 & 556 \\ 57.25 & 53.5 \end{bmatrix} - \begin{bmatrix} 554.8 & 516.8 \\ 54.75 & 51 \end{bmatrix} = \begin{bmatrix} 39.2 & 39.2 \\ 2.5 & 2.5 \end{bmatrix}
$$

### 白噪声

如果对于所有的$t_1≠t_2$,随机变量$X(t_1)$独立于随机变量 $X(t_2)$,那么$X(t)$被称为白噪声。否则,$X(t)$被称为有色噪声。

这里的“白”类比的是光，白光包含所有频率的可见光。就听觉上的“白噪声”而言，白噪声包含人耳可听范围内（20Hz 到 20kHz）所有频率的声音，且能量分布均匀。比如老式电视机的雪花屏/沙沙声，下雨声等

白噪声有如下基本性质：  

零均值：对所有时间$t$，期望为$0$

同方差性： 方差是恒定的，不随时间变化。 

无自相关性： 在不同时间点上的协方差为零（即没有线性关系）。 

在卡尔曼滤波中，噪声项是驱动系统动态和影响测量的核心随机变量。下面分别给出过程噪声和观测噪声的数学定义及其协方差表达式。 

**过程噪声**

过程噪声通常加在状态方程中，用于描述模型的不确定性或外部扰动。

定义$\mathbf{w}_k \in \mathbb{R}^n$ 为过程噪声向量。它是一个零均值的白噪声序列，即$E[{w}_k]=0$。

它的协方差矩阵为：

$$
\begin{aligned}
E[\mathbf{w}_k \mathbf{w}_j^T] =
\begin{cases}
\mathbf{Q}_k, & k = j \\
\mathbf{0}, & k \neq j
\end{cases}
\end{aligned}
$$

各部分含义：

$\mathbf{Q}_k$：过程噪声协方差矩阵，是一个实对称半正定矩阵。

对角线元素 $[\mathbf{Q}k]{ii}$：表示第 $i$ 个状态变量所受过程噪声的方差，反映了该状态分量随机波动的强度。

非对角线元素 $[\mathbf{Q}k]{ij}$：表示在同一时刻，第 $i$ 个状态变量与第 $j$ 个状态变量的过程噪声之间的协方差。如果非零，说明不同维度的噪声源之间存在相关性。


**观测噪声**

观测噪声加在观测方程(输出方程)中，描述传感器测量误差。

定义$\mathbf{v}_k \in \mathbb{R}^m$ 为观测噪声向量。它是一个零均值的白噪声序列，即$E[\mathbf{v}_k]=0$。

它的协方差矩阵为：  

$$
\begin{aligned}
E[\mathbf{v}_k \mathbf{v}_j^T] =
\begin{cases} 
\mathbf{R}_k, & k = j \\
0, & k \neq j
\end{cases}
\end{aligned}
$$

各部分含义：

$\mathbf{R}_k$：观测噪声协方差矩阵，是一个实对称正定矩阵（通常假设正定以保证滤波器的更新步骤稳定）。

对角线元素 $[\mathbf{R}k]{ii}$：表示第 $i$ 个传感器的测量方差，反映了该传感器的精度（数值越大，代表测量噪声越强，可信度越低）。

非对角线元素 $[\mathbf{R}k]{ij}$：表示在同一时刻，第 $i$ 个传感器与第 $j$ 个传感器的测量误差之间的协方差。如果不同传感器的误差源是独立的，则这些非对角线元素为 0，此时 $\mathbf{R}_k$ 是一个对角矩阵。


在标准卡尔曼滤波中，通常假设过程噪声与观测噪声在任何时刻都不相关：

$$
\begin{aligned}
E[\mathbf{w}_k \mathbf{v}_j^T] = \mathbf{0} \quad \text{对于所有 } k, j
\end{aligned}
$$

### 递推最小二乘估计

本节将要讨论如何基于带噪声的测量值去估计一个常量。例如,假设我们有一个电阻,但是我们不知道其电阻值是多少。我们用一个万用表多次测量它的阻值,但是因为这个万用表质量不是特别好,所以测量值是带噪声的。在这个例子里,我们可能只需要估计一个标量,但是通常情况下,我们会去估计一个常向量。

把这个例子用数学形式描述,假设$x$是一个固定的但是值是未知的真值向量，$y$是一个包含噪声的测量值向量，$v$是噪声向量，那么我们如何获得$x$的最佳估计值$\hat{x}$？假设$y$是$x$的线性组合与噪声$v$的和，那么我们有：

$$
y_k=H_kx+v_k  
$$


其中$k$代表第$k$步的向量。  

不难理解，这个模型表达的意义就是测量值是真值经过测量矩阵$H_k$变换后加上白噪声后的值。为方便起见，举一个标量的例子。比如，我们要测一个桌子的面积，假设真值为$2$。  

$k=1$时，由于没有对齐，导致真值经过$H_k$矩阵(尺子)后是$2.1$，再加上一些不可抗力因素（白噪声），最后的测量值为$2.15$.

$k=2$时，这次由于尺子热胀冷缩，导致真值经过$H_k$矩阵(尺子)后是$1.9$，再加上一些不可抗力因素（白噪声），最后的测量值为$1.95$.

依次类推......


同时线性的递推估计值可以写成如下形式:

$$
\hat x_{k}=\hat x_{k-1}  +K_k(y_k-H_k\hat x_{k-1})
$$

也就是说,我们基于上一步的估计值$\hat x_{k-1}$和新获得的测量$y_k$来计算$\hat x_{k}$，$K_k$是是待确定的增益矩阵。而$(y_k-H_k\hat x_{k-1})$被称为修正项。如果修正项为零,或者增益矩阵为零,那么估计值的大小在由$k-1$步到$k$步则不会改变。

在矩阵$(y_k-H_k\hat x_{k-1})$中，$y_k$是作为$k$时刻的测量值，而$H_k\hat x_{k-1}$代表的是用$k-1$时刻的估计值$\hat x_{k-1}$在测量矩阵$H_k$下，预测在$k$时刻的测量值。怎么理解呢，我们假设$k-1$时刻的估计值$\hat x_{k-1}$是准的，那么$\hat x_{k-1}=x$，此时矩阵$(y_k-H_k\hat x_{k-1})$只剩下白噪声。若$k-1$时刻的估计值$\hat x_{k-1}$不准，那么就会产生白噪声和别的信息，因此$(y_k-H_k\hat x_{k-1})$也被称作新息。

在我们计算最佳增益矩阵$K_k$, 之前,让我们考虑一下线性递推估计器的估计误差均值。估计误差均值可以表示为：

$$
\begin{aligned}
E(\varepsilon_{x,k}) &= E(x - \hat{x}_k) = E(x - \hat{x}_{k-1} - K_k(y_k - H_k\hat{x}_{k-1}))\\
&= E(\varepsilon_{x,k-1} - K_k(H_kx + v_k - H_k\hat{x}_{k-1}))\\
&= E(\varepsilon_{x,k-1} - K_kH_k(x - \hat{x}_{k-1}) - K_kv_k) \\
&= (I - K_kH_k)E(\varepsilon_{x,k-1}) - K_kE(v_k)
\end{aligned}
$$


从式子可以看出，若$E(v_k)=0$，并且$E(\varepsilon_{x,k-1})=0$，那么$E(\varepsilon_{x,k})=0$。换句话说，如果测量值噪声$E(v_k)$对所有$k$都是零均值的，并且$x$的初始估计设置等于$x$的期望值$[\hat{x_0} =E(x)]$，那么$\hat{x}$的期望值对所有$k$而言都等于$x$。因此，这种估计是无偏估计。

在卡尔曼滤波的假设中，所有噪声都是白噪声，其具有零均值的性质，因此第一个条件满足。  

对于第二个条件，若初始估计无偏，那么递推下去都是无偏的，但是实际过程中，初始估计很可能是有偏的，那么怎么满足呢？关键在于矩阵$(I - K_kH_k)$的谱半径小于1，根据矩阵的性质，递推下去，这一项就会收敛到零矩阵(渐进无偏)。(对于完全可观测的线性系统，如果噪声协方差正定、模型准确、增益按卡尔曼公式计算，那么误差递推矩阵$(I - K_kH_k)$的谱半径小于$1$，估计误差指数收敛。若系统部分不可观测，那么谱半径就等于$1$，在不可观测方向不收敛。这部分证明比较难，从实用主义讲，利用结论就行)

我们选取$K_k$的最优标准是使$k$时刻的估计误差的方差和最小（最小均方误差准则）。（实际上，由这个最优标准推导出的 $K_k$ 自然能保证矩阵 $(I - K_kH_k)$ 的谱半径小于 $1$）那么：  

$$
\begin{aligned}
J_k &= E[(x_1 - \hat{x}_1)^2] + \cdots + E[(x_n - \hat{x}_n)^2] \\
&= E(\varepsilon_{x_1,k}^2 + \cdots + \varepsilon_{x_n,k}^2) = E(\varepsilon_{x,k}^T \varepsilon_{x,k}) \\
&= E[\text{Tr}(\varepsilon_{x,k} \varepsilon_{x,k}^T)]  \\
&=\text{Tr}P_k
\end{aligned}
$$

定义$P_k$为估计误差的协方差矩阵。实际上，$P_k$就是$k$时刻误差$\varepsilon_{x,k}$的自相关矩阵，又因为是无偏估计，误差的期望为$0$，因此计算协方差矩阵的公式中只剩下自相关矩阵。  

利用估计误差均值的结果($\varepsilon_{x,k}=(I - K_kH_k)\varepsilon_{x,k-1} - K_kv_k$)，有：  

$$
\begin{aligned}
P_k &= E(\varepsilon_{x,k} \varepsilon_{x,k}^T) \\
&= E\{[(I - K_k H_k) \varepsilon_{x,k-1} - K_k v_k][(I - K_k H_k) \varepsilon_{x,k-1} - K_k v_{k}]^T\} \\
&= (I - K_k H_k) E(\varepsilon_{x,k-1} \varepsilon_{x,k-1}^T)(I - K_k H_k)^T \\
&\quad - K_k E(v_k \varepsilon_{x,k-1}^T)(I - K_k H_k)^T - (I - K_k H_k) E(\varepsilon_{x,k-1} v_k^T) K_k^T \\
&\quad + K_k E(v_k v_k^T) K_k^T
\end{aligned}
$$

注意到，$k-1$时刻的估计误差$(\varepsilon_{x,k-1})$独立于$k$时刻的测量噪声$v_k$。所以，  

$$
\begin{aligned}
E(v_k \varepsilon_{x,k-1}^T) = E(v_k)E(\varepsilon_{x,k-1}) = 0
\end{aligned}
$$

因此

$$
\begin{aligned}
P_k = (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T
\end{aligned}
$$

其中$R_k=E(v_k v_k^T)$，是测量噪声$v_k$的协方差。这就是最小二乘估计误差的协方差递推计算公式。这和我们的直觉是一致的:如果测量噪声增加了($R_k$增加),那么估计值的不确定性也会增加($P_k$增加)。

还记得上文的$J_k$吗，它等于$\text{Tr}P_k$，而$P_k=(I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T$。我们需要找出一个$K_k$使$J_k$最小。

如果$B$是对称的，那么$\frac{\partial \text{Tr}(ABA^T)}{\partial A} = 2AB$，利用此式:  

$$
\begin{aligned}
\frac{\partial J_k}{\partial K_k} = 2 \left( I - K_k H_k \right) P_{k-1} \left( -H_k^T \right) + 2K_k R_k
\end{aligned}
$$

其中前一项的求导需要用到链式法则，具体过程如下：  

$$
\begin{aligned}
A &= I - K_k H_k \\
P_k^{(1)} &= A P_{k-1} A^T \\
\frac{\partial \text{Tr}(P_k^{(1)})}{\partial K_k} &= \frac{\partial \text{Tr}(A P_{k-1} A^T)}{\partial A} \cdot \frac{\partial A}{\partial K_k} \\
\frac{\partial \text{Tr}(A P_{k-1} A^T)}{\partial A} &= 2A P_{k-1} \\
\frac{\partial A}{\partial K_k} &= -H_k^T \\
\frac{\partial \text{Tr}(P_k^{(1)})}{\partial K_k} &= 2A P_{k-1} (-H_k^T) = 2(I - K_k H_k) P_{k-1} (-H_k^T)
\end{aligned}
$$

由于$J_k$关于$K_k$是凸函数，因此令其微分为0，即可求出使$J_k$最小的$K_k$。

$$
\begin{aligned}
K_k R_k &= (I - K_k H_k) P_{k-1} H_k^T \\
K_k (R_k + H_k P_{k-1} H_k^T) &= P_{k-1} H_k^T 
\end{aligned}
$$

那么，$K_k$就等于：

$$
K_k = P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1}
$$

同时，$P_k$与$K_k$具有不同的形式，尽管这些形式在数学上是统一的，但从计算角度来看，它们各具优势。具体推导过程见后文章节“估计误差协方差矩阵与卡尔曼增益矩阵不同形式的推导”。

总之，$P_k$与$K_k$具有如下不同的形式：  

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber \\
&= (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1} \nonumber \\
&= (I - K_k H_k) P_{k-1} \\
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \nonumber \\
&= P_k H_k^T R_k^{-1}
\end{aligned}
$$

## 线性离散时间系统  

假设有下列线性离散时间系统:  

$$
\begin{aligned}
x_k &= F_{k-1}x_{k-1} + G_{k-1}u_{k-1} + w_{k-1} 
\end{aligned}
$$

${w_{k-1}}$是白噪声。

状态$x_k$的均值会随时间如何变化？对两边取期望：  

$$
\begin{align}
\bar x{_k} = E(\bar x{_k}) = F_{k-1}\bar x_{k-1} + G_{k-1}u_{k-1}\tag{1}
\end{align}
$$

$x_k$的协方差随时间会有怎样的变化？

$$
\begin{aligned}
& \left(x_{k}-\bar{x}_{k}\right)\left(x_{k}-\bar{x}_{k}\right)^{\mathrm{T}} \\
= & \left(F_{k-1} x_{k-1}+G_{k-1} u_{k-1}+w_{k-1}-\bar{x}_{k}\right)\left(F_{k-1} x_{k-1}+G_{k-1} u_{k-1}+w_{k-1}-\bar{x}_{k}\right)^{\mathrm{T}} \\
= & {\left[F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)+w_{k-1}\right]\left[F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)+w_{k-1}\right]^{\mathrm{T}} } \\
= & F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)\left(x_{k-1}-\bar{x}_{k-1}\right)^{\mathrm{T}} F_{k-1}^{\mathrm{T}}+w_{k-1} w_{k-1}^{\mathrm{T}}+ \\
& F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right) w_{k-1}^{\mathrm{T}}+w_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)^{\mathrm{T}} F_{k-1}^{\mathrm{T}}
\end{aligned}
$$

上式的期望即$x_k$的协方差，考虑到 $(x_{k-1}-\bar{x}_{k-1})$ 与 $w\_{k-1}$ 不相关。 

$$
\begin{align}
P_k = E[(x_k - \bar{x}_k)(x_k - \bar{x}_k)^T] = F_{k-1}P_{k-1}F_{k-1}^T + Q_{k-1}\tag{2}
\end{align}
$$


## 离散卡尔曼滤波  

> Smoothing, Filtering and Prediction: Estimating The Past, Present and Future.——Garry A. Einicke

定义如下线性离散状态空间：

$$
\begin{aligned}
x_k &= F_{k-1}x_{k-1} + G_{k-1}u_{k-1} + w_{k-1} \\
y_k &= H_kx_k + v_k
\end{aligned}
$$

${w_k}$,${v_k}$是零均值、不相关白噪声。其定义与性质已在白噪声一节说明，于此不再赘述。

最小均方误差意义下(这是卡尔曼滤波始终追求的目标)，最优估计就是条件期望。因此有如下定义：

如果我们利用包括$k$时刻和$k$时刻以前的量测值估计$x_k$,那么能得到一个后验估计，记为$\hat x{^+}$。如果我们利用$k$时刻之前(不包括$k$)的量测值来估计$x_k$,那么能得到一个先验估计,记为$\hat x{^-}$。获得后验状态估计的方法是在$k$时刻和$k$时刻以前的量测值的条件下计算的$x_k$的期望值,同样的，获得先验状态估计的方法是在时间$k$时刻以前的量测值的条件下计算的$x_k$的期望值。

$$
\begin{aligned}
\hat{x}_k^+ &= E\{x_k \mid y_1, y_2, \cdots, y_k\}= \text{后验估计}\\
\hat{x}_k^- &= E\{x_k \mid y_1, y_2, \cdots, y_{k-1}\}= \text{先验估计}
\end{aligned}
$$

请注意，$\hat x{^+}$与$\hat x{^-}$都是对$x_k$的估计。而且都是等于对$x_k$的条件期望，只是条件不一样（后验估计多了一个$k$时刻的量测值的条件）

我们用$P_k$代表估计误差的协方差，$P_k^-$表示$\hat{x}_k^-$的估计误差协方差，$P_k^+$表示$\hat{x}_k^+$的估计误差协方差：  

$$
\begin{aligned}
P_k^- &= E[(x_k - \hat{x}_k^-)(x_k - \hat{x}_k^-)^T] \\
P_k^+ &= E[(x_k - \hat{x}_k^+)(x_k - \hat{x}_k^+)^T]
\end{aligned}
$$

以$\hat{x}_0^+$作为未获得任何量测值时的初始估计（第一个量测值在$k=1$时获得），并假设它是${x}_0$的最优估计。那么如何通过$\hat{x}_0^+$计算$\hat{x}_1^-$?回顾式$(1)$的公式，不难得到：  

$$
\begin{aligned}
\bar x_{1} = F_{0}\bar x_{0} + G_{0}u_{0}
\end{aligned}
$$

又因为$\hat x_1^- = E(x_1)=\bar x_{1},\hat x_0^+ = E(x_0)= \bar x_{0}$。因此，  

$$
\begin{aligned}
\hat{x}_1^- = F_0 \hat{x}_0^+ + G_0 u_0
\end{aligned}
$$

由此不难得到一般递推式:

$$
\begin{align}
\hat{x}_k^- = F_{k-1} \hat{x}_{k-1}^+ + G_{k-1} u_{k-1}\tag{3}
\end{align}
$$

这被称为$\hat{x}$的时间更新方程。

接着需要计算$P$的时间更新方程，以$x_0$的估计协方差$P_0^+$开始。如果完全了解初始状态，那么$P_0^+=0$，如果对初始状态没有信息，那么$P_0^+=∞I$。$P_0^+$代表初始估计值的不确定性。那么如何通过$P_0^+$计算$P_1^-$?回顾式$(2)$的公式，不难得到：

$$
\begin{aligned}
P_1  = F_{0}P_{0}F_{0}^T + Q_{0}
\end{aligned}
$$

考虑到$\hat x_1^- = E(x_1)=\bar x_{1},\hat x_0^+ = E(x_0)= \bar x_{0}$以及$P_k^-$和$P_k^+$的表达式，上式可写为：

$$
\begin{aligned}
P_1^- = F_{0}P_0^+F_{0}^T + Q_{0}
\end{aligned}
$$

由此不难得到一般递推式：

$$
\begin{align}
P_{k}^- = F_{k-1}P_{k-1}^+F_{k-1}^T + Q_{k-1}\tag{4}
\end{align}
$$

上式即$P$的时间更新方程。

现在已经得到$\hat{x}$和$P$的时间更新方程，接下来需要二者的量测更新方程。请回顾递推最小二乘估计的$K_k$与$P_k$以及$\hat x_{k}$的公式：

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber \\
&= (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1} \nonumber \\
&= (I - K_k H_k) P_{k-1} \\
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \nonumber \\
&= P_k H_k^T R_k^{-1}\\
\hat x_{k}&=\hat x_{k-1}  +K_k(y_k-H_k\hat x_{k-1})
\end{aligned}
$$


其中，$\hat x_{k-1}$和 $P_{k-1}$ 是在量测 $y_k$ 之前状态的估计和协方差，$\hat x_k$ 和 $P_k$ 是在量测 $y_k$ 之后的估计值和协方差。在这一章，$\hat x_k^-$ 和 $P_k^-$ 是在利用测量 $y_k$ 之前状态的估计值和协方差，$\hat  x_k^+$ 和 $P_k^+$ 是在利用测量 $y_k$ 之后状态的估计值和协方差。这些关系在下表给出。

| 最小二乘估计 | 卡尔曼滤波器 |
| :--- | :--- |
| $\hat{x}_{k-1} = (y_k \quad \text{处理之前的估计值})$ | $\hat{x}_k^- = \text{先验估计}$ |
| $P_{k-1} = (y_k \quad \text{处理之前的协方差估计})$ | $P_k^- = \text{先验协方差估计}$ |
| $\hat{x}_k = (y_k \quad \text{处理之后的估计值})$ | $\hat{x}_k^+ = \text{后验估计}$ |
| $P_k = (y_k \quad \text{处理之后的协方差估计值})$ | $P_k^+ = \text{后验协方差估计}$ |


若我们按照表格的对应关系，把递推最小二乘估计的变量换成这一章的变量，就得到量测更新方程，即：  

$$
\begin{align}
K_k &= P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1} = P_k^+ H_k^T R_k^{-1}\tag{5} \\
\hat{x}_k^+ &= \hat{x}_k^- + K_k (y_k - H_k \hat{x}_k^-)\tag{6} \\
P_k^+ &= (I - K_k H_k) P_k^{-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber\\
&= [(P_k^{-1})^{-1} + H_k^T R_k^{-1} H_k]^{-1} = (I - K_k H_k) P_k^{-1}\tag{7}
\end{align}
$$

若把式$(3)-(7)$综合，就得到了卡尔曼滤波的五个方程：  

$$
\begin{align}
\hat{x}_k^- &= F_{k-1} \hat{x}_{k-1}^+ + G_{k-1} u_{k-1} \tag{I}\\
P_k^- &= F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1} \tag{II}\\
K_k &= P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1} = P_k^+ H_k^T R_k^{-1} \tag{III}\\
\hat{x}_k^+ &= \hat{x}_k^- + K_k (y_k - H_k \hat{x}_k^-) \tag{IV}\\
P_k^+ &= (I - K_k H_k) P_k^- (I - K_k H_k)^T + K_k R_k K_k^T \nonumber\\
&= [(P_k^-)^{-1} + H_k^T R_k^{-1} H_k]^{-1}\nonumber \\
&= (I - K_k H_k) P_k^- \tag{V}
\end{align}
$$


## 算法与实例

(1)初始化($k=0$)，设定$\hat x_0^+$与$P_0^+$（如果没有先验信息，取合理初值，并根据对初始值的信任程度，调节$P_0^+$的大小）

(2)对于$k=1,2,3......$，迭代执行：

时间更新（预测）：$I,II$

测量更新（校正）：$III，IV，V$

为了更好的理解这个过程，举一个例子。

**问题定义与模型建立**

考虑一维运动目标，采用常速度（CV）模型。状态向量包含位置和速度：

$$\mathbf{x} = \begin{bmatrix} p \\ v \end{bmatrix}$$

状态方程（离散时间，采样间隔 $T = 1s$）：

$$\mathbf{x}_k = F_{k-1}\mathbf{x}_{k-1} + \mathbf{w}_{k-1}, \quad \mathbf{w}_{k-1} \sim N(0, Q)$$

其中状态矩阵：

$$F_{k-1} = \begin{bmatrix} 1 & T \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$$

过程噪声协方差矩阵 $Q$ 反映了速度波动的可能性。为简化，取较小值：

$$Q = \begin{bmatrix} 0 & 0 \\ 0 & 0.01 \end{bmatrix}$$

输出方程(测量方程)（仅能测量位置）：

$$y_k = H_k\mathbf{x}_k + v_k, \quad v_k \sim N(0, R)$$

其中测量矩阵：

$$H_k = \begin{bmatrix} 1 & 0 \end{bmatrix}$$

测量噪声方差 $R = 10$（假设传感器精度一般）。

**初始化（$k=0$）**
   
初始状态估计值（猜测）：

$$\hat{\mathbf{x}}_0^+ = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$$

即初始位置猜测为$0$，初始速度猜测为$1 m/s$。

初始误差协方差矩阵（反映对初始猜测的信任程度）：

$$P_0 = \begin{bmatrix} 10 & 0  \\0 & 5 \end{bmatrix}$$

表示位置不确定性较大（方差$10$），速度也有一定不确定性（方差$5$），且假设位置和速度的初始估计误差不相关。

**第一时刻循环（$k=1$）**


根据CV模型预测当前状态：

$$\hat{\mathbf{x}}_1^- = F_0 \hat{\mathbf{x}}_0^+ = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$$

物理含义：根据上一时刻位置$0$和速度1，预测$1$秒后位置变为$1$，速度保持不变为$1$。

**协方差预测**

先验误差协方差矩阵：

$$P_1^- = F_0 P_0^+ F_0^T + Q_0$$

逐步计算：

首先计算 $F_0 P_0^+$：

$$F_0 P_0^+ = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 10 & 0 \\ 0 & 5 \end{bmatrix} = \begin{bmatrix} 10 & 5 \\ 0 & 5 \end{bmatrix}$$

再乘以 $F_0^T$：

$$F_0 P_0^+ F_0^T = \begin{bmatrix} 10 & 5 \\ 0 & 5 \end{bmatrix} \begin{bmatrix} 1 & 0\\ 1 & 1 \end{bmatrix} =  \begin{bmatrix} 15 & 5 \\ 5 & 5 \end{bmatrix}$$

加上过程噪声 $Q$：

$$P_1^- = \begin{bmatrix} 15 & 5 \\ 5 & 5 \end{bmatrix} + \begin{bmatrix} 0 & 0 \\ 0 & 0.01 \end{bmatrix} = \begin{bmatrix} 15 & 5 \\ 5 & 5.01 \end{bmatrix}$$

**卡尔曼增益计算**

首先计算 $ H P_1^- H^T + R$：


$$(H_1 P_1^-) H_1^T + R_1 = \begin{bmatrix} 15 & 5 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} + 10 = 15 + 10 = 25$$

卡尔曼增益 

$$K_1 = P_1^- H_1^T (H_1 P_1^- H_1^T + R_1)^{-1} $$：

$$K_1 = \begin{bmatrix} 15 \\ 5 \end{bmatrix} \times \frac{1}{25} = \begin{bmatrix} 0.6 \\ 0.2 \end{bmatrix}$$

物理含义：增益的第一项$0.6$表示对位置测量的信任程度中等（因预测位置不确定性$15$，测量噪声$10$）；第二项$0.2$表示通过位置测量可以间接修正速度估计，这正是CV模型能估计速度的关键。

**状态更新**

假设第一次测量值 $y_1 = 3$（真实位置未知，但传感器读数为$3$）。

先计算新息：

$$y_1 - H_1\hat{\mathbf{x}}_1^- = 3 - \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = 3 - 1 = 2$$

后验状态估计：

$$\hat{\mathbf{x}}_1^+ = \hat{\mathbf{x}}_1^- + K_1 (y_1 - H_1\hat{\mathbf{x}}_1^-） = \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \begin{bmatrix} 0.6 \\ 0.2 \end{bmatrix} \times 2 =  \begin{bmatrix} 2.2 \\ 1.4 \end{bmatrix}$$

物理含义：位置从预测的$1$修正为$2.2$，更接近测量值$3$；速度从预测的$1$修正为$1.4$，因为测量值大于预测，暗示实际速度可能比预测的快。

**协方差更新**

后验误差协方差矩阵：

$$P_1^+ = (I - K_1 H_1) P_1^-$$

$$P_1^+ = \begin{bmatrix} 6 & 2 \\ 2 & 4.01 \end{bmatrix}$$

物理含义：位置不确定性从$15$降至$6$，速度不确定性从$5.01$降至$4.01$，且位置和速度的估计误差产生正相关（协方差$2$），这符合物理直觉——位置偏大时速度也倾向于偏大。

然后利用$P_1^+ $和$\hat x_1^+$作为$k=2$时刻的初始条件，经过简单计算后$k=2$时位置从预测的$2.2$修正为$4.1247$，速度从$1.4$修正为$1.625$。通过两次循环，尽管仅测量位置，速度估计已从初始的$1$逐步调整，开始跟踪真实运动趋势。

通过上述两步循环，我们清晰地看到卡尔曼滤波的五步循环：状态预测→协方差预测→增益计算→状态更新→协方差更新，每一步都有明确的数学计算和物理含义。


## 相关代码 

考虑用卡尔曼滤波估计一个二维平面的轨迹。（使用位置传感器与速度传感器）  

卡尔曼滤波循环的代码如下：

```matlab
for k = 1:steps
   
    % 预测步
    x_pred = F * x_est;
    P_pred = F * P * F' + Q;
    
     % 当前测量值（GPS位置 + 速度计）
    y_k = [x_meas(k+1); y_meas(k+1); vx_meas(k+1); vy_meas(k+1)]; 
    
    % 更新步
    K = P_pred * H' / (H * P_pred * H' + R);
    x_est = x_pred + K * (y_k - H * x_pred);
    P = (eye(n) - K * H) * P_pred;
    
    % 存储估计位置
    x_kalman(:, k+1) = x_est(1:2);
end

```

完整代码请参考：https://github.com/Alyxx17/Kalman-Filter-for-Beginners

## 常见问题  

### $F_k$矩阵的实现方式 

如果系统具有明确的物理方程（如倒立摆、RLC电路、阻尼弹簧振子），直接使用物理模型建立连续时间域的状态空间再转换为离散时间状态空间即可。

但在实际的雷达跟踪、导航、视频目标跟踪中，我们面对的对象往往是非合作目标，飞机什么时候加速、什么时候拐弯，是飞行员决定的，没有物理方程能直接算出飞行员下一秒的意图。对于这种情况，我们可以从泰勒展开出发。

假设目标的运动轨迹是光滑曲线，根据泰勒展开，

$$
\begin{aligned}
x(t_k) = x(t_{k-1}) + \dot{x}(t_{k-1})\Delta t + \frac{1}{2}\ddot{x}(t_{k-1})\Delta t^2 + \frac{1}{6}\dddot{x}(t_{k-1})\Delta t^3 + \dots
\end{aligned}
$$

这个展开式揭示了“下一刻状态”与“当前状态及各阶导数”之间的精确关系。

然而，卡尔曼滤波的状态向量维度是有限的，我们无法承载无穷多阶导数。因此，我们不得不做出截断：

**零阶模型**：只保留$x(t_{k-1})$。假设高阶项均为0。适用于状态几乎不变的系统。即$x_k=x_{k-1}$

**一阶模型（匀速/常速模型 CV）**:保留到一阶导（速度）项，即假设$\ddot{x}$及更高阶项为0。核心假设：加速度为0，速度不变。

可以表示为：

$$
\begin{aligned}
x_k &= 
\begin{bmatrix}
p \\
v
\end{bmatrix}_k \\
F &= 
\begin{bmatrix}
1 & \Delta t \\
0 & 1
\end{bmatrix}
\end{aligned}
$$

**二阶模型（匀加速/常加速模型 CA）**:保留到二阶导（加速度）项，即假设$\dddot{x}$及更高阶项为0。核心假设：加加速度为0，加速度不变。

可以表示为：

$$
\begin{aligned}
x_k &= 
\begin{bmatrix}
p \\
v \\
a
\end{bmatrix}_k \\
F &= 
\begin{bmatrix}
1 & \Delta t & 0.5\Delta t^2 \\
0 & 1 & \Delta t \\
0 & 0 & 1
\end{bmatrix}
\end{aligned}
$$

如果只靠泰勒截断，模型误差其实挺大的——现实世界中哪有永远匀速或匀加速的运动？但是得益于高采样频率带来的‘微观线性化’红利，可以将任意复杂运动在极短间隔内近似为匀速或匀加速过程。

值得指出的是，采用CV或CA模型时，卡尔曼滤波即使在没有速度与加速度传感器的情况下依然能够稳定工作。它并非依赖传统的位置差分来计算这些导数，而是通过卡尔曼增益实时、最优地融合模型预测与观测信息，实现对未测量状态（如速度、加速度）的动态估计。虽然在仅有位置传感器时，估计的性能（如收敛速度与精度）会有所下降，但这并不影响算法在理论上的完备性和工程上的实用性。

### 卡尔曼滤波中各项参数的意义以及如何调整？

在卡尔曼滤波中，主要调整的参数为过程噪声协方差矩阵$Q_k$，测量噪声协方差矩阵$R_k$以及误差协方差初始值$P_0$。

过程噪声协方差矩阵$Q_k$：代表你对系统模型（如运动方程）的信任程度。其值越大，说明你认为模型噪声越大，越依赖测量值。对象动态性强（如急转弯、强机动）应适当调大，让滤波器快速响应变化。对象平稳（如匀速直线运动）应调小，让滤波器更平滑地滤除噪声。

测量噪声协方差矩阵$R_k$：代表你对传感器读数准确度的信任程度。其值越大，说明你认为传感器噪声大、不可信。传感器精度差、易受干扰时应调大，避免被异常测量值带偏。传感器精度高、环境稳定时应调小，充分发挥传感器的优势。

误差协方差初始值$P_0$： 代表你对最初猜想的信心程度。如果对初始状态非常确定（如从已知静止点启动），$P$设小。如果完全不知道初始状态，$P$设大。只要滤波器是稳定的，$P$通常会在迭代几次后迅速收敛，初始值的影响相对有限。

$R_k$通常可以通过离线实验测得（例如，静止时采集传感器数据，计算其方差）。相对容易确定。先把$R_k$固定，再根据滤波效果微调$Q_k$。


### 卡尔曼滤波与龙伯格观测器的区别与联系

从控制理论的角度审视，卡尔曼滤波本质上是一种时变的、最优的龙伯格观测器。它们共享相同的闭环结构：都是利用“实测输出”与“模型预测输出”之间的偏差来修正状态估计。区别在于，传统观测器的增益是基于极点配置预先算好的“固定值”，旨在保证误差衰减速度；而卡尔曼增益则是基于噪声统计特性在线递推计算的“动态值”，旨在最小化估计误差的方差。可以说，当系统面临随机噪声的挑战时，卡尔曼滤波为我们提供了一种系统性的方法来自动计算出那个“最合适的观测器增益”。

龙伯格观测器的观测器方程可以写为：

$$
\hat{x}_{k}=A \hat{x}_{k-1}+B u_{k-1}+L\left(y_{k-1}-C \hat{x}_{k-1}\right)
$$

而卡尔曼滤波的预测-修正方程为：

$$
\begin{array}{l}
\tilde{x}_{k}=A \hat{x}_{k-1}+B u_{k-1} \\
\hat{x}_{k}=\tilde{x}_{k}+L\left(y_{k}-C \tilde{x}_{k}\right)
\end{array}
$$

可以看到二者在结构上完全等价。因此，从结构上看，卡尔曼滤波本质上就是一种增益时变的、统计意义最优的当前型状态观测器。

| 维度 | 一般观测器（如龙伯格） | 卡尔曼滤波器 | 核心区别总结 |
| :--- | :--- | :--- | :--- |
| **设计目标** | **极点配置：** 让估计误差以**指定的速度**衰减到零。 | **方差最小化：** 让估计误差的**方差**在统计意义下最小。 | **确定性 vs 随机性** |
| **增益计算** | **固定增益：** 基于离线计算的极点位置，得到固定的增益矩阵 \( $L$ \)。 | **时变增益：** 在线递推计算卡尔曼增益 \( $K_k$ \)，随系统置信度变化。 | **静态 vs 动态** |
| **处理噪声** | 通常将噪声视为扰动，通过增大增益来压制，但会放大测量噪声。 | **显式建模：** 明确区分过程噪声 \( $Q$ \) 和测量噪声 \( $R$ \)，并据此优化。 | **被动抗扰 vs 主动滤波** |
| **数学模型** | 假设系统是确定性的 \( $\dot{x} = Ax + Bu$ \)。 | 假设系统受随机扰动 \( $w$ \) 和 \( $v$ \) 影响。 | **无噪声项 vs 有噪声项** |

### 卡尔曼滤波与(递推)最小二乘法的区别与联系   

| 维度 | 最小二乘法 | 递推最小二乘法 | 卡尔曼滤波 |
| :--- | :--- | :--- | :--- |
| **数据处理方式** | **批处理：** 攒够所有数据，一次性算完。 | **递推：** 来一个数据，更新一次结果。 | **递推：** 来一个数据，更新一次结果。 |
| **是否考虑时间** | **不考虑：** 数据只是"点"，顺序任意。 | **弱考虑：** 虽然递推，但所有数据权重均等。 | **强考虑：** 有权重衰减，旧数据可以逐渐"被遗忘"。 |
| **模型利用** | **纯数据驱动：** 只用量测方程 \( $y = Hx + v$ \)。 | **纯数据驱动：** 同上，不预测未来。 | **模型+数据：** 既有状态方程 \( $x_k = Ax_{k-1}+w$ \)，又有量测方程。 |
| **适用场景** | 离线标定、曲线拟合。 | 在线参数辨识（如系统辨识）。 | 实时状态估计（如导航、跟踪）。 |

从估计理论的角度审视，卡尔曼滤波可以看作是最小二乘法在动态系统上的自然延伸。当系统的状态不随时间变化（即$A=I,Q=0$)时卡尔曼滤波完全退化为递推加权最小二乘法(从本文关于卡尔曼滤波的推导过程来看，就是基于递推最小二乘法推出了卡尔曼滤波的量测修正方程)。两者的核心目标都是使误差的平方和最小——只不过最小二乘法最小化的是测量残差，寻找一个固定的最优参数；而卡尔曼滤波最小化的是过程噪声和测量噪声的联合加权平方和，寻找一条随时间演变的最优轨迹。

值得一提的是高斯在1801年(高斯此时24岁，看看人家的24岁，XD)用最小二乘法预测了谷神星轨道，百年之后，思想一脉相承。卡尔曼滤波解决了阿波罗飞船的轨道估计问题。

### 卡尔曼滤波的本质：加权平均  

假设我们现在要测量某个物体的物理量，有两个独立的测量值：

$$
\begin{aligned}
x_1 &\sim N(\mu, \sigma_1^2) \\
x_2 &\sim N(\mu, \sigma_2^2)
\end{aligned}
$$

这两个测量值都是无偏的（均值都是$\mu$），但精度不同（方差不同）。

最自然的想法(可以证明，在最小方差意义下也是最优估计)就是加权平均这两个测量值：  

$$
x=kx_1+(1-k)x_2，k∈(0,1)
$$

取方差：

$$
\begin{aligned}
D(x) &= k^2\sigma_1^2 + (1 - k)^2\sigma_2^2 \\
D(x) &= k^2\sigma_1^2 + (k^2 - 2k + 1)\sigma_2^2 \\
D(x) &= k^2(\sigma_1^2 + \sigma_2^2) - 2k\sigma_2^2 + \sigma_2^2
\end{aligned}
$$

我们想让$D(x)$最小，显然$D(x)$是关于$k$的二次函数，容易求得$D(x)$最小时的k取值为：  

$$
\begin{aligned}
k = \frac{\sigma_2^2}{\sigma_1^2 + \sigma_2^2}
\end{aligned}
$$

这就是最优权重。

把最优权重回代，即有最小方差(以下三个等号后式子都是等价的)：

$$
\begin{aligned}
D(x) &= k\sigma_1^2\\
 &= k^2\sigma_1^2 + (1 - k)^2\sigma_2^2 \\
 &= (1 - k)\sigma_2^2
\end{aligned}
$$

具体对应关系如下：


| 卡尔曼滤波 | 一维加权平均数 |
| --- | --- |
| $\hat x_k^- = F_{k-1}\hat x_{k-1}^{+} + G_{k-1}u_{k-1}$ | |
| $\hat{x}_k^+ = \hat{x}_k^- + K_k(y_k - H_k\hat{x}_k^-)$ | $x = x_2 + k(x_1 - x_2)$ |
| $P_k^- = F_{k-1}P_{k-1}^{+}F_{k-1}^T + Q_{k-1}$ | $D(cX) = c^2D(X)$ 和 $D(X+Y) = D(X)+D(Y)$ |
| $K_k = P_k^-H_k^T(H_kP_k^-H_k^T + R_k)^{-1}$ | $k = \frac{\sigma_2^2}{\sigma_1^2 + \sigma_2^2}$ |
| $P_k^+ = (I - K_kH_k)P_k^-$ | $D(x) = (1-k)\sigma_2^2$ |
| $P_k^+ = (I - K_kH_k)P_k^-(I - K_kH_k)^T + K_kR_kK_k^T$ | $D(x) = k^2\sigma_1^2 + (1-k)^2\sigma_2^2$ |


### 卡尔曼滤波的适用场合

卡尔曼滤波并非放之四海而皆准的万能算法，但当面对的问题满足以下特征时，它往往是最优选择：

第一，系统是动态的且可建模。 需要知道状态如何随时间演化——无论是简单的匀速运动，还是复杂的动力学方程。这个模型不必完美，但必须存在。

第二，传感器提供带噪声的观测。 如果有完美的测量，就不需要滤波；如果完全没有测量，那就只能靠模型开环预测。卡尔曼滤波恰好填补了两者之间的空白。

第三，需要实时估计。卡尔曼滤波的递推特性使其适合在线应用——每来一个测量，就更新一次估计，延迟极低。

第四，噪声特性近似高斯。 标准卡尔曼滤波假设过程噪声和测量噪声均为高斯分布。如果实际噪声严重偏离这一假设（如重尾分布、多模态），则需考虑粒子滤波等其他方法。

具体上比较适合GPS/INS组合导航、无人机姿态解算、车辆定位， 雷达跟踪飞机、视频跟踪行人、自动驾驶感知与降噪、信道均衡等领域。

当然，这只是经典卡尔曼滤波的适用场景，在面对一些非线性场合可以采用扩展卡尔曼滤波（EKF），无迹卡尔曼滤波（UKF）等改善方式或者别的滤波方法。

## 估计误差协方差矩阵与卡尔曼增益矩阵不同形式的推导

$P_k$形式二：  

$$
\begin{aligned}
P_{k} & =\left(I-K_{k} H_{k}\right) P_{k-1}\left(I-K_{k} H_{k}\right)^{T}+K_{k} R_{k} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} H_{k} P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} R_{k} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k}\left(H_{k} P_{k-1} H_{k}^{T}+R_{k}\right) K_{k}^{T} \\
& \stackrel{(1)}{=} P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} S_{k} K_{k}^{T} \\
& \stackrel{(2)}{=} P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+P_{k-1} H_{k}^{T} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1} \\
& =\left(I-K_{k} H_{k}\right) P_{k-1}
\end{aligned}
$$

其中：  

$$
\begin{aligned}
\text{(1) } S_k &= H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } K_k &= P_{k-1} H_k^T S_k^{-1} \text{，得 } K_k S_k K_k^T = P_{k-1} H_k^T K_k^T
\end{aligned}
$$

$P_k$形式三： 

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k H_k P_{k-1} H_k^T K_k^T + K_k R_k K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k (H_k P_{k-1} H_k^T + R_k) K_k^T \\
&\stackrel{(1)}{=} P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k S_k K_k^T \\
&\stackrel{(2)}{=} P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + P_{k-1} H_k^T K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} \\
&= (I - K_k H_k) P_{k-1} \\
&\stackrel{(3)}{=} (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1}
\end{aligned}
$$

其中：  

$$
\begin{aligned}
\text{(1) } S_k = H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } K_k = P_{k-1} H_k^T S_k^{-1} \\
\text{(3) 由矩阵求逆引理:} (I - K_k H_k) P_{k-1} = (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1}
\end{aligned}
$$

$K_k$形式二：

$$
\begin{aligned}
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \\
&\stackrel{(1)}{=} P_{k-1} H_k^T S_k^{-1} \\
&\stackrel{(2)}{=} P_k (I - K_k H_k)^{-1} H_k^T S_k^{-1} \\
&\stackrel{(3)}{=} P_k H_k^T (I - H_k K_k)^{-1} S_k^{-1} \\
&\stackrel{(4)}{=} P_k H_k^T (I + H_k P_{k-1} H_k^T R_k^{-1})^{-1} S_k^{-1} \\
&\stackrel{(5)}{=} P_k H_k^T R_k^{-1}
\end{aligned}
$$

其中： 

$$
\begin{aligned}
\text{(1) } S_k &= H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } P_{k-1} &= (I - K_k H_k)^{-1} P_k \\
\text{(3) 利用 } (I - K_k H_k)^{-1} H_k^T &= H_k^T (I - H_k K_k)^{-1} \\
\text{(4) 代入 } K_k &= P_{k-1} H_k^T S_k^{-1} \text{，得 } H_k K_k = H_k P_{k-1} H_k^T S_k^{-1} \text{，故 } I - H_k K_k = (H_k P_{k-1} H_k^T + R_k)^{-1} R_k \text{，其逆为 } R_k^{-1} (H_k P_{k-1} H_k^T + R_k) \text{，代入化简} \\
\text{(5) 化简得 } P_k H_k^T R_k^{-1}
\end{aligned}
$$

## 参考   

最优状态估计:卡尔曼,H∞及非线性滤波(美)西蒙(Simon,D.)著;张勇刚,李宁,奔粤阳译.一北京:国防工业出版社,2013.5 ISBN 978-7-118-08808-3

阿波罗11号制导计算机中登月模块（Luminary099）原始代码的卡尔曼滤波部分：https://github.com/chrislgarry/Apollo-11/blob/master/Luminary099/KALMAN_FILTER.agc

网上相关资源  

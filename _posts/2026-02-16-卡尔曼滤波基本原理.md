---
title: 卡尔曼滤波基本原理
date: 2026-02-16 20:00:00 +0800
categories: [控制,算法]
tags: [控制]
math: true  # <-- 就是这一行，启用本页的数学公式渲染
---

## 序  

> That's one small step for man, one giant leap for mankind. ——Neil Alden Armstrong


![](assets/img/study/Aldrin_Apollo_11_original.webp)

1969年7月20日，阿姆斯特朗踏上月球，说出了这句传世之言。

全世界都听到了这句话。但很少有人知道，在他踏出这一步的瞬间，有一双看不见的手，正在默默计算着他的位置。

那不是人的手。

是卡尔曼滤波(Kalman Filter)。  

登月舱从月球轨道下降到地表，整个过程需要实时知道两件事：我在哪，我要去哪。

但测量是不准的——雷达有噪声，惯性测量单元有漂移。如果只信传感器，会偏；如果只信数学模型，也会偏。

卡尔曼滤波做的事，就是把这两个不太靠谱的信息来源捏在一起，捏出一个足够靠谱的答案。

它不是什么神秘的黑魔法。它是一套数学公式，写成了代码，烧进了阿波罗制导计算机的只读内存里。

这是那段代码的部分：  

![](assets/img/study/code.webp)

这段代码写在人类登月前。它用AGC汇编语言写成，运行在只有2K内存的计算机上，以今天的标准看简陋得不可思议。

但它管用。

它把阿姆斯特朗送到了静海，又把他带回了家。



## 预备知识

### 矩阵  

矩阵的基本概念，运算规则等。  

### 期望  

在概率论和统计学中，一个离散性随机变量的期望是试验中每次可能的结果乘以其结果概率的总和。例如，掷一枚公平的六面骰子，其每次“点数”的期望是$3.5$，计算如下：

$$
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
= \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
$$

如果$X$是连续的随机变量，存在一个相应的概率密度函数$f(x)$，若积分$\int\limits_{-∞}^{∞} xf(x)dx$绝对收敛，那么$X$的期望可以计算为：  

$$
E(X)=\int\limits_{-∞}^{∞} xf(x)dx
$$

是针对于连续的随机变量的，与离散随机变量的期望的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。

期望$E$是线性函数，即:$E(aX+bY)=aE(X)+bE(Y)$  

期望也可表示为：$\bar X$。

### 方差   

方差是刻画随机变量在其中心位置附近散布程度的数学特征，反映了随机变量取值的离散程度。方差提供了衡量数据在平均值附近波动程度的方法：方差越大，数据分布越分散，波动越大；方差越小，数据越集中，波动越小。为了消除偏差带来的正负抵消，方差对偏离均值的差值进行平方后取期望。方差的常用符号有：$σ^2，s^2，Var(X)，D(X)$。方差的计算公式如下：

$$
Var(x)=E[(X-\mu )^2]
$$

其中$\mu=E(X)$。


### 协方差矩阵

在概率论与统计学中，协方差（Covariance）用于衡量随机变量间的相关程度。  

设$X$和$Y$为两个实值随机变量，它们的协方差定义为它们偏离各自期望值的乘积的期望值，即：  

$$
Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
$$

可以看出协方差的形式类似于方差，只是把其中的一个随机变量$X$换成了$Y$。

通过利用期望的线性性质，协方差的计算公式可以简化为：  

$$
\begin{aligned}
Cov(X, Y) &= E[(X - E[X])(Y - E[Y])] \\
&= E[XY - XE[Y] - E[X]Y + E[X]E[Y]] \\
&= E[XY] - E[X]E[Y] - E[X]E[Y] + E[X]E[Y] \\
&= E[XY] - E[X]E[Y]
\end{aligned}
$$

当协方差为正值时，表明随机变量X和Y倾向于同时偏离其平均值，呈正相关关系；反之，若协方差为负值，则表明一个变量高于平均值时，另一个倾向于低于平均值，呈负相关关系。如果协方差为零，这意味着两个变量之间没有线性关系。

若随机变量$X$与$Y$是相互独立的，那么$Cov(X, Y)=0$。反之，如果两个变量的协方差为$0$（即不相关），不能推出它们相互独立。  

下图表明了协方差的意义

![协方差的意义](assets/img/study/Covariance_trends.webp)  

这个可以推广到随机变量是向量的情况。在这种情况下,之前定义的标量变成向量和矩阵。已知一个$n$维的随机变量$X$和一个$m$维的随机变量$Y$(假设$X$和$Y$都是列向量),它们的互相关矩阵定义为：  

$$
R_{XY} = E(XY^T) =
\begin{bmatrix}
E(X_1 Y_1) & \cdots & E(X_1 Y_m) \\
\vdots & \ddots & \vdots \\
E(X_n Y_1) & \cdots & E(X_n Y_m)
\end{bmatrix}
$$
 
协方差矩阵定义为:   

$$
C_{XY} = E[(X - \overline{X})(Y - \overline{Y})^T] = E(XY^T) - \overline{X}·\overline{Y}^T
$$

自协方差矩阵都是对称矩阵，互协方差矩阵不一定对称，甚至不是方阵。

这个$n$维的随机变量的自相关矩阵定义为:  

$$
R_X = E[XX^T] =
\begin{bmatrix}
E[X_1^2] & \cdots & E[X_1 X_n] \\
\vdots & \ddots & \vdots \\
E[X_n X_1] & \cdots & E[X_n^2]
\end{bmatrix}
$$

为了更好的理解协方差矩阵，接下来举一个例子。假设如下数据：  

| 类型   | 概率 $p$ | $X₁$ (学习时长) | $X₂$ (作业完成率) | $Y₁$ (数学) | $Y₂$ (语文) |
| :----- | :----- | :------------ | :-------------- | :-------- | :-------- |
| 学霸   | 0.2    | 12            | 1.0 (100%)      | 95        | 90        |
| 普通生 | 0.5    | 8             | 0.8 (80%)       | 75        | 70        |
| 学困生 | 0.3    | 4             | 0.5 (50%)       | 55        | 50        |

**步骤1：计算每类的 $XY^T$（外积）**

学霸：

$$
XY^T = \begin{bmatrix} 12 \\ 1.0 \end{bmatrix} \begin{bmatrix} 95 & 90 \end{bmatrix} = \begin{bmatrix} 1140 & 1080 \\95 & 90 \end{bmatrix}
$$

普通生：

$$
XY^T = \begin{bmatrix} 8 \\ 0.8 \end{bmatrix} \begin{bmatrix} 75 & 70 \end{bmatrix} = \begin{bmatrix} 600 & 560 \\ 60 & 56 \end{bmatrix}
$$

学困生：

$$
XY^T = \begin{bmatrix} 4 \\ 0.5 \end{bmatrix} \begin{bmatrix} 55 & 50 \end{bmatrix} = \begin{bmatrix} 220 & 200 \\ 27.5 & 25 \end{bmatrix}
$$

**步骤2：计算 $E(XY^T)$（加权平均）**

$$
E(XY^T) = 0.2 \times \begin{bmatrix} 1140 & 1080 \\ 95 & 90 \end{bmatrix} + 0.5 \times \begin{bmatrix} 600 & 560 \\ 60 & 56 \end{bmatrix} + 0.3 \times \begin{bmatrix} 220 & 200 \\ 27.5 & 25 \end{bmatrix}
$$

逐元素计算：

$E(X_1 Y_1) = 0.2 \times 1140 + 0.5 \times 600 + 0.3 \times 220 = 594$

$E(X_1 Y_2) = 0.2 \times 1080 + 0.5 \times 560 + 0.3 \times 200 = 556$

$E(X_2 Y_1) = 0.2 \times 95 + 0.5 \times 60 + 0.3 \times 27.5 = 57.25$

$E(X_2 Y_2) = 0.2 \times 90 + 0.5 \times 56 + 0.3 \times 25 = 53.5$

所以：

$$
R_{XY} = E(XY^T) = \begin{bmatrix} 594 & 556 \\ 57.25 & 53.5 \end{bmatrix}
$$

**步骤3：计算各自的期望 $E(X)$ 和 $E(Y)$** 

$$
E(X) = \begin{bmatrix} E(X_1) \\ E(X_2) \end{bmatrix} = \begin{bmatrix} 0.2 \times 12 + 0.5 \times 8 + 0.3 \times 4 \\ 0.2 \times 1.0 + 0.5 \times 0.8 + 0.3 \times 0.5 \end{bmatrix} = \begin{bmatrix} 7.6 \\ 0.75 \end{bmatrix}
$$

$$
E(Y) = \begin{bmatrix} E(Y_1) \\ E(Y_2) \end{bmatrix} = \begin{bmatrix} 0.2 \times 95 + 0.5 \times 75 + 0.3 \times 55 \\ 0.2 \times 90 + 0.5 \times 70 + 0.3 \times 50 \end{bmatrix} = \begin{bmatrix} 73 \\ 68 \end{bmatrix}
$$

**步骤4：计算 $E(X)E(Y)^T$**

$$
E(X)E(Y)^T = \begin{bmatrix} 7.6 \\ 0.75 \end{bmatrix} \begin{bmatrix} 73 & 68 \end{bmatrix} = \begin{bmatrix} 7.6 \times 73 & 7.6 \times 68 \\ 0.75 \times 73 & 0.75 \times 68 \end{bmatrix} = \begin{bmatrix} 554.8 & 516.8 \\ 54.75 & 51 \end{bmatrix}
$$

**步骤5：计算协方差矩阵 $C_{XY}$**

$$
C_{XY} = E(XY^T) - E(X)E(Y)^T = \begin{bmatrix} 594 & 556 \\ 57.25 & 53.5 \end{bmatrix} - \begin{bmatrix} 554.8 & 516.8 \\ 54.75 & 51 \end{bmatrix} = \begin{bmatrix} 39.2 & 39.2 \\ 2.5 & 2.5 \end{bmatrix}
$$

### 白噪声

如果对于所有的$t_1≠t_2$,随机变量$X(t_1)$独立于随机变量 $X(t_2)$,那么$X(t)$被称为白噪声。否则,$X(t)$被称为有色噪声。

这里的“白”类比的是光，白光包含所有频率的可见光。就听觉上的“白噪声”而言，白噪声包含人耳可听范围内（20Hz 到 20kHz）所有频率的声音，且能量分布均匀。比如老式电视机的雪花屏/沙沙声，下雨声等

白噪声有如下基本性质：  

零均值：对所有时间$t$，期望为$0$

同方差性： 方差是恒定的，不随时间变化。 

无自相关性： 在不同时间点上的协方差为零（即没有线性关系）。 

在卡尔曼滤波中，噪声项是驱动系统动态和影响测量的核心随机变量。下面分别给出过程噪声和观测噪声的数学定义及其协方差表达式。 

**过程噪声**

过程噪声通常加在状态方程中，用于描述模型的不确定性或外部扰动。

定义$\mathbf{w}_k \in \mathbb{R}^n$ 为过程噪声向量。它是一个零均值的白噪声序列，即$E[{w}_k]=0$。

它的协方差矩阵为：

$$
\begin{aligned}
E[\mathbf{w}_k \mathbf{w}_j^T] =
\begin{cases}
\mathbf{Q}_k, & k = j \\
\mathbf{0}, & k \neq j
\end{cases}
\end{aligned}
$$

各部分含义：

$\mathbf{Q}_k$：过程噪声协方差矩阵，是一个实对称半正定矩阵。

对角线元素 $[\mathbf{Q}k]{ii}$：表示第 $i$ 个状态变量所受过程噪声的方差，反映了该状态分量随机波动的强度。

非对角线元素 $[\mathbf{Q}k]{ij}$：表示在同一时刻，第 $i$ 个状态变量与第 $j$ 个状态变量的过程噪声之间的协方差。如果非零，说明不同维度的噪声源之间存在相关性。


**观测噪声**

观测噪声加在观测方程(输出方程)中，描述传感器测量误差。

定义$\mathbf{v}_k \in \mathbb{R}^m$ 为观测噪声向量。它是一个零均值的白噪声序列，即$E[\mathbf{v}_k]=0$。

它的协方差矩阵为：  

$$
\begin{aligned}
E[\mathbf{v}_k \mathbf{v}_j^T] =
\begin{cases} 
\mathbf{R}_k, & k = j \\
0, & k \neq j
\end{cases}
\end{aligned}
$$

各部分含义：

$\mathbf{R}_k$：观测噪声协方差矩阵，是一个实对称正定矩阵（通常假设正定以保证滤波器的更新步骤稳定）。

对角线元素 $[\mathbf{R}k]{ii}$：表示第 $i$ 个传感器的测量方差，反映了该传感器的精度（数值越大，代表测量噪声越强，可信度越低）。

非对角线元素 $[\mathbf{R}k]{ij}$：表示在同一时刻，第 $i$ 个传感器与第 $j$ 个传感器的测量误差之间的协方差。如果不同传感器的误差源是独立的，则这些非对角线元素为 0，此时 $\mathbf{R}_k$ 是一个对角矩阵。


在标准卡尔曼滤波中，通常假设过程噪声与观测噪声在任何时刻都不相关：

$$
\begin{aligned}
E[\mathbf{w}_k \mathbf{v}_j^T] = \mathbf{0} \quad \text{对于所有 } k, j
\end{aligned}
$$

### 递推最小二乘估计

本节将要讨论如何基于带噪声的测量值去估计一个常量。例如,假设我们有一个电阻,但是我们不知道其电阻值是多少。我们用一个万用表多次测量它的阻值,但是因为这个万用表质量不是特别好,所以测量值是带噪声的。在这个例子里,我们可能只需要估计一个标量,但是通常情况下,我们会去估计一个常向量。

把这个例子用数学形式描述,假设$x$是一个固定的但是值是未知的真值向量，$y$是一个包含噪声的测量值向量，$v$是噪声向量，那么我们如何获得$x$的最佳估计值$\hat{x}$？假设$y$是$x$的线性组合与噪声$v$的和，那么我们有：

$$
y_k=H_kx+v_k  
$$


其中$k$代表第$k$步的向量。  

不难理解，这个模型表达的意义就是测量值是真值经过测量矩阵$H_k$变换后加上白噪声后的值。为方便起见，举一个标量的例子。比如，我们要测一个桌子的面积，假设真值为$2$。  

$k=1$时，由于没有对齐，导致真值经过$H_k$矩阵(尺子)后是$2.1$，再加上一些不可抗力因素（白噪声），最后的测量值为$2.15$.

$k=2$时，这次由于尺子热胀冷缩，导致真值经过$H_k$矩阵(尺子)后是$1.9$，再加上一些不可抗力因素（白噪声），最后的测量值为$1.95$.

依次类推......


同时线性的递推估计值可以写成如下形式:

$$
\hat x_{k}=\hat x_{k-1}  +K_k(y_k-H_k\hat x_{k-1})
$$

也就是说,我们基于上一步的估计值$\hat x_{k-1}$和新获得的测量$y_k$来计算$\hat x_{k}$，$K_k$是是待确定的增益矩阵。而$(y_k-H_k\hat x_{k-1})$被称为修正项。如果修正项为零,或者增益矩阵为零,那么估计值的大小在由$k-1$步到$k$步则不会改变。

在矩阵$(y_k-H_k\hat x_{k-1})$中，$y_k$是作为$k$时刻的测量值，而$H_k\hat x_{k-1}$代表的是用$k-1$时刻的估计值$\hat x_{k-1}$在测量矩阵$H_k$下，预测在$k$时刻的测量值。怎么理解呢，我们假设$k-1$时刻的估计值$\hat x_{k-1}$是准的，那么$\hat x_{k-1}=x$，此时矩阵$(y_k-H_k\hat x_{k-1})$只剩下白噪声。若$k-1$时刻的估计值$\hat x_{k-1}$不准，那么就会产生白噪声和别的信息，因此$(y_k-H_k\hat x_{k-1})$也被称作新息。

在我们计算最佳增益矩阵$K_k$, 之前,让我们考虑一下线性递推估计器的估计误差均值。估计误差均值可以表示为：

$$
\begin{aligned}
E(\varepsilon_{x,k}) &= E(x - \hat{x}_k) = E(x - \hat{x}_{k-1} - K_k(y_k - H_k\hat{x}_{k-1}))\\
&= E(\varepsilon_{x,k-1} - K_k(H_kx + v_k - H_k\hat{x}_{k-1}))\\
&= E(\varepsilon_{x,k-1} - K_kH_k(x - \hat{x}_{k-1}) - K_kv_k) \\
&= (I - K_kH_k)E(\varepsilon_{x,k-1}) - K_kE(v_k)
\end{aligned}
$$


从式子可以看出，若$E(v_k)=0$，并且$E(\varepsilon_{x,k-1})=0$，那么$E(\varepsilon_{x,k})=0$。换句话说，如果测量值噪声$E(v_k)$对所有$k$都是零均值的，并且$x$的初始估计设置等于$x$的期望值$[\hat{x_0} =E(x)]$，那么$\hat{x}$的期望值对所有$k$而言都等于$x$。因此，这种估计是无偏估计。

在卡尔曼滤波的假设中，所有噪声都是白噪声，其具有零均值的性质，因此第一个条件满足。  

对于第二个条件，若初始估计无偏，那么递推下去都是无偏的，但是实际过程中，初始估计很可能是有偏的，那么怎么满足呢？关键在于矩阵$(I - K_kH_k)$的谱半径小于1，根据矩阵的性质，递推下去，这一项就会收敛到零矩阵(渐进无偏)。(对于完全可观测的线性系统，如果噪声协方差正定、模型准确、增益按卡尔曼公式计算，那么误差递推矩阵$(I - K_kH_k)$的谱半径小于$1$，估计误差指数收敛。若系统部分不可观测，那么谱半径就等于$1$，在不可观测方向不收敛。这部分证明比较难，从实用主义讲，利用结论就行)

我们选取$K_k$的最优标准是使$k$时刻的估计误差的方差和最小（最小均方误差准则）。（实际上，由这个最优标准推导出的 $K_k$ 自然能保证矩阵 $(I - K_kH_k)$ 的谱半径小于 $1$）那么：  

$$
\begin{aligned}
J_k &= E[(x_1 - \hat{x}_1)^2] + \cdots + E[(x_n - \hat{x}_n)^2] \\
&= E(\varepsilon_{x_1,k}^2 + \cdots + \varepsilon_{x_n,k}^2) = E(\varepsilon_{x,k}^T \varepsilon_{x,k}) \\
&= E[\text{Tr}(\varepsilon_{x,k} \varepsilon_{x,k}^T)]  \\
&=\text{Tr}P_k
\end{aligned}
$$

定义$P_k$为估计误差的协方差矩阵。实际上，$P_k$就是$k$时刻误差$\varepsilon_{x,k}$的自相关矩阵，又因为是无偏估计，误差的期望为$0$，因此计算协方差矩阵的公式中只剩下自相关矩阵。  

利用估计误差均值的结果($\varepsilon_{x,k}=(I - K_kH_k)\varepsilon_{x,k-1} - K_kv_k$)，有：  

$$
\begin{aligned}
P_k &= E(\varepsilon_{x,k} \varepsilon_{x,k}^T) \\
&= E\{[(I - K_k H_k) \varepsilon_{x,k-1} - K_k v_k][(I - K_k H_k) \varepsilon_{x,k-1} - K_k v_{k}]^T\} \\
&= (I - K_k H_k) E(\varepsilon_{x,k-1} \varepsilon_{x,k-1}^T)(I - K_k H_k)^T \\
&\quad - K_k E(v_k \varepsilon_{x,k-1}^T)(I - K_k H_k)^T - (I - K_k H_k) E(\varepsilon_{x,k-1} v_k^T) K_k^T \\
&\quad + K_k E(v_k v_k^T) K_k^T
\end{aligned}
$$

注意到，$k-1$时刻的估计误差$(\varepsilon_{x,k-1}$独立于$k$时刻的测量噪声$v_k$。所以，  

$$
\begin{aligned}
E(v_k \varepsilon_{x,k-1}^T) = E(v_k)E(\varepsilon_{x,k-1}) = 0
\end{aligned}
$$

因此

$$
\begin{aligned}
P_k = (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T
\end{aligned}
$$

其中$R_k=E(v_k v_k^T)$，是测量噪声$v_k$的协方差。这就是最小二乘估计误差的协方差递推计算公式。这和我们的直觉是一致的:如果测量噪声增加了($R_k$增加),那么估计值的不确定性也会增加($P_k$增加)。

还记得上文的$J_k$吗，它等于$\text{Tr}P_k$，而$P_k=(I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T$。我们需要找出一个$K_k$使$J_k$最小。

如果$B$是对称的，那么$\frac{\partial \text{Tr}(ABA^T)}{\partial A} = 2AB$，利用此式:  

$$
\begin{aligned}
\frac{\partial J_k}{\partial K_k} = 2 \left( I - K_k H_k \right) P_{k-1} \left( -H_k^T \right) + 2K_k R_k
\end{aligned}
$$

其中前一项的求导需要用到链式法则，具体过程如下：  

$$
\begin{aligned}
A &= I - K_k H_k \\
P_k^{(1)} &= A P_{k-1} A^T \\
\frac{\partial \text{Tr}(P_k^{(1)})}{\partial K_k} &= \frac{\partial \text{Tr}(A P_{k-1} A^T)}{\partial A} \cdot \frac{\partial A}{\partial K_k} \\
\frac{\partial \text{Tr}(A P_{k-1} A^T)}{\partial A} &= 2A P_{k-1} \\
\frac{\partial A}{\partial K_k} &= -H_k^T \\
\frac{\partial \text{Tr}(P_k^{(1)})}{\partial K_k} &= 2A P_{k-1} (-H_k^T) = 2(I - K_k H_k) P_{k-1} (-H_k^T)
\end{aligned}
$$

由于$J_k$关于$K_k$是凸函数，因此令其微分为0，即可求出使$J_k$最小的$K_k$。

$$
\begin{aligned}
K_k R_k &= (I - K_k H_k) P_{k-1} H_k^T \\
K_k (R_k + H_k P_{k-1} H_k^T) &= P_{k-1} H_k^T 
\end{aligned}
$$

那么，$K_k$就等于：

$$
K_k = P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1}
$$

同时，$P_k$与$K_k$具有不同的形式，尽管这些形式在数学上是统一的，但从计算角度来看，它们各具优势。具体推导过程见后文章节“估计误差协方差矩阵与卡尔曼增益矩阵不同形式的推导”。

总之，$P_k$与$K_k$具有如下不同的形式：  

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber \\
&= (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1} \nonumber \\
&= (I - K_k H_k) P_{k-1} \\
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \nonumber \\
&= P_k H_k^T R_k^{-1}
\end{aligned}
$$

## 线性离散时间系统  

假设有下列线性离散时间系统:  

$$
\begin{aligned}
x_k &= F_{k-1}x_{k-1} + G_{k-1}u_{k-1} + w_{k-1} 
\end{aligned}
$$

${w_{k-1}}$是白噪声。

状态$x_k$的均值会随时间如何变化？对两边取期望：  

$$
\begin{align}
\bar x{_k} = E(\bar x{_k}) = F_{k-1}\bar x_{k-1} + G_{k-1}u_{k-1}\tag{1}
\end{align}
$$

$x_k$的协方差随时间会有怎样的变化？

$$
\begin{aligned}
& \left(x_{k}-\bar{x}_{k}\right)\left(x_{k}-\bar{x}_{k}\right)^{\mathrm{T}} \\
= & \left(F_{k-1} x_{k-1}+G_{k-1} u_{k-1}+w_{k-1}-\bar{x}_{k}\right)\left(F_{k-1} x_{k-1}+G_{k-1} u_{k-1}+w_{k-1}-\bar{x}_{k}\right)^{\mathrm{T}} \\
= & {\left[F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)+w_{k-1}\right]\left[F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)+w_{k-1}\right]^{\mathrm{T}} } \\
= & F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)\left(x_{k-1}-\bar{x}_{k-1}\right)^{\mathrm{T}} F_{k-1}^{\mathrm{T}}+w_{k-1} w_{k-1}^{\mathrm{T}}+ \\
& F_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right) w_{k-1}^{\mathrm{T}}+w_{k-1}\left(x_{k-1}-\bar{x}_{k-1}\right)^{\mathrm{T}} F_{k-1}^{\mathrm{T}}
\end{aligned}
$$

上式的期望即$x_k$的协方差，考虑到 $(x_{k-1}-\bar{x}_{k-1})$ 与 $w\_{k-1}$ 不相关。 

$$
\begin{align}
P_k = E[(x_k - \bar{x}_k)(x_k - \bar{x}_k)^T] = F_{k-1}P_{k-1}F_{k-1}^T + Q_{k-1}\tag{2}
\end{align}
$$


## 离散卡尔曼滤波  

> Smoothing, Filtering and Prediction: Estimating The Past, Present and Future.——Garry A. Einicke

定义如下线性离散状态空间：

$$
\begin{aligned}
x_k &= F_{k-1}x_{k-1} + G_{k-1}u_{k-1} + w_{k-1} \\
y_k &= H_kx_k + v_k
\end{aligned}
$$

${w_k}$,${v_k}$是零均值、不相关白噪声。其定义与性质已在白噪声一节说明，于此不再赘述。

最小均方误差意义下(这是卡尔曼滤波始终追求的目标)，最优估计就是条件期望。因此有如下定义：

如果我们利用包括$k$时刻和$k$时刻以前的量测值估计$x_k$,那么能得到一个后验估计，记为$\hat x{^+}$。如果我们利用$k$时刻之前(不包括$k$)的量测值来估计$x_k$,那么能得到一个先验估计,记为$\hat x{^-}$。获得后验状态估计的方法是在$k$时刻和$k$时刻以前的量测值的条件下计算的$x_k$的期望值,同样的，获得先验状态估计的方法是在时间$k$时刻以前的量测值的条件下计算的$x_k$的期望值。

$$
\begin{aligned}
\hat{x}_k^+ &= E\{x_k \mid y_1, y_2, \cdots, y_k\}= \text{后验估计}\\
\hat{x}_k^- &= E\{x_k \mid y_1, y_2, \cdots, y_{k-1}\}= \text{先验估计}
\end{aligned}
$$

请注意，$\hat x{^+}$与$\hat x{^-}$都是对$x_k$的估计。而且都是等于对$x_k$的条件期望，只是条件不一样（后验估计多了一个$k$时刻的量测值的条件）

我们用$P_k$代表估计误差的协方差，$P_k^-$表示$\hat{x}_k^-$的估计误差协方差，$P_k^+$表示$\hat{x}_k^+$的估计误差协方差：  

$$
\begin{aligned}
P_k^- &= E[(x_k - \hat{x}_k^-)(x_k - \hat{x}_k^-)^T] \\
P_k^+ &= E[(x_k - \hat{x}_k^+)(x_k - \hat{x}_k^+)^T]
\end{aligned}
$$

以$\hat{x}_0^+$作为未获得任何量测值时的初始估计（第一个量测值在$k=1$时获得），并假设它是${x}_0$的最优估计。那么如何通过$\hat{x}_0^+$计算$\hat{x}_1^-$?回顾式$(1)$的公式，不难得到：  

$$
\begin{aligned}
\bar x_{1} = F_{0}\bar x_{0} + G_{0}u_{0}
\end{aligned}
$$

又因为$\hat x_1^- = E(x_1)=\bar x_{1},\hat x_0^+ = E(x_0)= \bar x_{0}$。因此，  

$$
\begin{aligned}
\hat{x}_1^- = F_0 \hat{x}_0^+ + G_0 u_0
\end{aligned}
$$

由此不难得到一般递推式:

$$
\begin{align}
\hat{x}_k^- = F_{k-1} \hat{x}_{k-1}^+ + G_{k-1} u_{k-1}\tag{3}
\end{align}
$$

这被称为$\hat{x}$的时间更新方程。

接着需要计算$P$的时间更新方程，以$x_0$的估计协方差$P_0^+$开始。如果完全了解初始状态，那么$P_0^+=0$，如果对初始状态没有信息，那么$P_0^+=∞I$。$P_0^+$代表初始估计值的不确定性。那么如何通过$P_0^+$计算$P_1^-$?回顾式$(2)$的公式，不难得到：

$$
\begin{aligned}
P_1  = F_{0}P_{0}F_{0}^T + Q_{0}
\end{aligned}
$$

考虑到$\hat x_1^- = E(x_1)=\bar x_{1},\hat x_0^+ = E(x_0)= \bar x_{0}$以及$P_k^-$和$P_k^+$的表达式，上式可写为：

$$
\begin{aligned}
P_1^- = F_{0}P_0^+F_{0}^T + Q_{0}
\end{aligned}
$$

由此不难得到一般递推式：

$$
\begin{align}
P_{k}^- = F_{k-1}P_{k-1}^+F_{k-1}^T + Q_{k-1}\tag{4}
\end{align}
$$

上式即$P$的时间更新方程。

现在已经得到$\hat{x}$和$P$的时间更新方程，接下来需要二者的量测更新方程。请回顾递推最小二乘估计的$K_k$与$P_k$以及$\hat x_{k}$的公式：

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber \\
&= (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1} \nonumber \\
&= (I - K_k H_k) P_{k-1} \\
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \nonumber \\
&= P_k H_k^T R_k^{-1}\\
\hat x_{k}&=\hat x_{k-1}  +K_k(y_k-H_k\hat x_{k-1})
\end{aligned}
$$


其中，$\hat x_{k-1}$和 $P_{k-1}$ 是在量测 $y_k$ 之前状态的估计和协方差，$\hat x_k$ 和 $P_k$ 是在量测 $y_k$ 之后的估计值和协方差。在这一章，$\hat x_k^-$ 和 $P_k^-$ 是在利用测量 $y_k$ 之前状态的估计值和协方差，$\hat  x_k^+$ 和 $P_k^+$ 是在利用测量 $y_k$ 之后状态的估计值和协方差。这些关系在下表给出。

| 最小二乘估计 | 卡尔曼滤波器 |
| :--- | :--- |
| $\hat{x}_{k-1} = (y_k \quad \text{处理之前的估计值})$ | $\hat{x}_k^- = \text{先验估计}$ |
| $P_{k-1} = (y_k \quad \text{处理之前的协方差估计})$ | $P_k^- = \text{先验协方差估计}$ |
| $\hat{x}_k = (y_k \quad \text{处理之后的估计值})$ | $\hat{x}_k^+ = \text{后验估计}$ |
| $P_k = (y_k \quad \text{处理之后的协方差估计值})$ | $P_k^+ = \text{后验协方差估计}$ |


若我们按照表格的对应关系，把递推最小二乘估计的变量换成这一章的变量，就得到量测更新方程，即：  

$$
\begin{align}
K_k &= P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1} = P_k^+ H_k^T R_k^{-1}\tag{5} \\
\hat{x}_k^+ &= \hat{x}_k^- + K_k (y_k - H_k \hat{x}_k^-)\tag{6} \\
P_k^+ &= (I - K_k H_k) P_k^{-1} (I - K_k H_k)^T + K_k R_k K_k^T \nonumber\\
&= [(P_k^{-1})^{-1} + H_k^T R_k^{-1} H_k]^{-1} = (I - K_k H_k) P_k^{-1}\tag{7}
\end{align}
$$

若把式$(3)-(7)$综合，就得到了卡尔曼滤波的五个方程：  

$$
\begin{align}
\hat{x}_k^- &= F_{k-1} \hat{x}_{k-1}^+ + G_{k-1} u_{k-1} \tag{I}\\
P_k^- &= F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1} \tag{II}\\
K_k &= P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1} = P_k^+ H_k^T R_k^{-1} \tag{III}\\
\hat{x}_k^+ &= \hat{x}_k^- + K_k (y_k - H_k \hat{x}_k^-) \tag{IV}\\
P_k^+ &= (I - K_k H_k) P_k^- (I - K_k H_k)^T + K_k R_k K_k^T \nonumber\\
&= [(P_k^-)^{-1} + H_k^T R_k^{-1} H_k]^{-1}\nonumber \\
&= (I - K_k H_k) P_k^- \tag{V}
\end{align}
$$


## 算法与实例

(1)初始化($k=0$)，设定$\hat x_0^+$与$P_0^+$（如果没有先验信息，取合理初值，并根据对初始值的信任程度，调节$P_0^+$的大小）

(2)对于$k=1,2,3......$，迭代执行：

时间更新（预测）：$I,II$

测量更新（校正）：$III，IV，V$

为了更好的理解这个过程，举一个例子。

**问题定义与模型建立**

考虑一维运动目标，采用常速度（CV）模型。状态向量包含位置和速度：

$$\mathbf{x} = \begin{bmatrix} p \\ v \end{bmatrix}$$

状态方程（离散时间，采样间隔 $T = 1s$）：

$$\mathbf{x}_k = F_{k-1}\mathbf{x}_{k-1} + \mathbf{w}_{k-1}, \quad \mathbf{w}_{k-1} \sim N(0, Q)$$

其中状态矩阵：

$$F_{k-1} = \begin{bmatrix} 1 & T \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$$

过程噪声协方差矩阵 $Q$ 反映了速度波动的可能性。为简化，取较小值：

$$Q = \begin{bmatrix} 0 & 0 \\ 0 & 0.01 \end{bmatrix}$$

输出方程(测量方程)（仅能测量位置）：

$$y_k = H_k\mathbf{x}_k + v_k, \quad v_k \sim N(0, R)$$

其中测量矩阵：

$$H_k = \begin{bmatrix} 1 & 0 \end{bmatrix}$$

测量噪声方差 $R = 10$（假设传感器精度一般）。

**初始化（$k=0$）**
   
初始状态估计值（猜测）：

$$\hat{\mathbf{x}}_0^+ = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$$

即初始位置猜测为$0$，初始速度猜测为$1 m/s$。

初始误差协方差矩阵（反映对初始猜测的信任程度）：

$$P_0 = \begin{bmatrix} 10 & 0  \\0 & 5 \end{bmatrix}$$

表示位置不确定性较大（方差$10$），速度也有一定不确定性（方差$5$），且假设位置和速度的初始估计误差不相关。

**第一时刻循环（$k=1$）**


根据CV模型预测当前状态：

$$\hat{\mathbf{x}}_1^- = F_0 \hat{\mathbf{x}}_0^+ = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$$

物理含义：根据上一时刻位置$0$和速度1，预测$1$秒后位置变为$1$，速度保持不变为$1$。

**协方差预测**

先验误差协方差矩阵：

$$P_1^- = F_0 P_0^+ F_0^T + Q_0$$

逐步计算：

首先计算 $F_0 P_0^+$：

$$F_0 P_0^+ = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 10 & 0 \\ 0 & 5 \end{bmatrix} = \begin{bmatrix} 10 & 5 \\ 0 & 5 \end{bmatrix}$$

再乘以 $F_0^T$：

$$F_0 P_0^+ F_0^T = \begin{bmatrix} 10 & 5 \\ 0 & 5 \end{bmatrix} \begin{bmatrix} 1 & 0\\ 1 & 1 \end{bmatrix} =  \begin{bmatrix} 15 & 5 \\ 5 & 5 \end{bmatrix}$$

加上过程噪声 $Q$：

$$P_1^- = \begin{bmatrix} 15 & 5 \\ 5 & 5 \end{bmatrix} + \begin{bmatrix} 0 & 0 \\ 0 & 0.01 \end{bmatrix} = \begin{bmatrix} 15 & 5 \\ 5 & 5.01 \end{bmatrix}$$

**卡尔曼增益计算**

首先计算 $ H P_1^- H^T + R$：


$$(H_1 P_1^-) H_1^T + R_1 = \begin{bmatrix} 15 & 5 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} + 10 = 15 + 10 = 25$$

卡尔曼增益 

$$K_1 = P_1^- H_1^T (H_1 P_1^- H_1^T + R_1)^{-1} $$：

$$K_1 = \begin{bmatrix} 15 \\ 5 \end{bmatrix} \times \frac{1}{25} = \begin{bmatrix} 0.6 \\ 0.2 \end{bmatrix}$$

物理含义：增益的第一项$0.6$表示对位置测量的信任程度中等（因预测位置不确定性$15$，测量噪声$10$）；第二项$0.2$表示通过位置测量可以间接修正速度估计，这正是CV模型能估计速度的关键。

**状态更新**

假设第一次测量值 $y_1 = 3$（真实位置未知，但传感器读数为$3$）。

先计算新息：

$$y_1 - H_1\hat{\mathbf{x}}_1^- = 3 - \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = 3 - 1 = 2$$

后验状态估计：

$$\hat{\mathbf{x}}_1^+ = \hat{\mathbf{x}}_1^- + K_1 (y_1 - H_1\hat{\mathbf{x}}_1^-） = \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \begin{bmatrix} 0.6 \\ 0.2 \end{bmatrix} \times 2 =  \begin{bmatrix} 2.2 \\ 1.4 \end{bmatrix}$$

物理含义：位置从预测的$1$修正为$2.2$，更接近测量值$3$；速度从预测的$1$修正为$1.4$，因为测量值大于预测，暗示实际速度可能比预测的快。

**协方差更新**

后验误差协方差矩阵：

$$P_1^+ = (I - K_1 H_1) P_1^-$$

$$P_1^+ = \begin{bmatrix} 6 & 2 \\ 2 & 4.01 \end{bmatrix}$$

物理含义：位置不确定性从$15$降至$6$，速度不确定性从$5.01$降至$4.01$，且位置和速度的估计误差产生正相关（协方差$2$），这符合物理直觉——位置偏大时速度也倾向于偏大。

然后利用$P_1^+ $和$\hat x_1^+$作为$k=2$时刻的初始条件，经过简单计算后$k=2$时位置从预测的$2.2$修正为$4.1247$，速度从$1.4$修正为$1.625$。通过两次循环，尽管仅测量位置，速度估计已从初始的$1$逐步调整，开始跟踪真实运动趋势。

通过上述两步循环，我们清晰地看到：卡尔曼滤波的五步循环：状态预测→协方差预测→增益计算→状态更新→协方差更新，每一步都有明确的数学计算和物理含义。


## 相关代码

## 常见问题  

### $F_k$矩阵的实现方式 

如果系统具有明确的物理方程（如倒立摆、RLC电路、阻尼弹簧振子），直接使用物理模型建立连续时间域的状态空间再转换为离散时间状态空间即可。

但在实际的雷达跟踪、导航、视频目标跟踪中，我们面对的对象往往是非合作目标，飞机什么时候加速、什么时候拐弯，是飞行员决定的，没有物理方程能直接算出飞行员下一秒的意图。对于这种情况，我们可以从泰勒展开出发。

假设目标的运动轨迹是光滑曲线，根据泰勒展开，

$$
\begin{aligned}
x(t_k) = x(t_{k-1}) + \dot{x}(t_{k-1})\Delta t + \frac{1}{2}\ddot{x}(t_{k-1})\Delta t^2 + \frac{1}{6}\dddot{x}(t_{k-1})\Delta t^3 + \dots
\end{aligned}
$$

这个展开式揭示了“下一刻状态”与“当前状态及各阶导数”之间的精确关系。

然而，卡尔曼滤波的状态向量维度是有限的，我们无法承载无穷多阶导数。因此，我们不得不做出截断：

**零阶模型**：只保留$x(t_{k-1})$。假设高阶项均为0。适用于状态几乎不变的系统。即$x_k=x_{k-1}$

**一阶模型（匀速/常速模型 CV）**:保留到一阶导（速度）项，即假设$\ddot{x}$及更高阶项为0。核心假设：加速度为0，速度不变。

可以表示为：

$$
\begin{aligned}
x_k &= 
\begin{bmatrix}
p \\
v
\end{bmatrix}_k \\
F &= 
\begin{bmatrix}
1 & \Delta t \\
0 & 1
\end{bmatrix}
\end{aligned}
$$

**二阶模型（匀加速/常加速模型 CA）**:保留到二阶导（加速度）项，即假设$\dddot{x}$及更高阶项为0。核心假设：加加速度为0，加速度不变。

可以表示为：

$$
\begin{aligned}
x_k &= 
\begin{bmatrix}
p \\
v \\
a
\end{bmatrix}_k \\
F &= 
\begin{bmatrix}
1 & \Delta t & 0.5\Delta t^2 \\
0 & 1 & \Delta t \\
0 & 0 & 1
\end{bmatrix}
\end{aligned}
$$

如果只靠泰勒截断，模型误差其实挺大的——现实世界中哪有永远匀速或匀加速的运动？但是得益于高采样频率带来的‘微观线性化’红利，可以将任意复杂运动在极短间隔内近似为匀速或匀加速过程。

值得指出的是，采用CV或CA模型时，卡尔曼滤波即使在没有速度与加速度传感器的情况下依然能够稳定工作。它并非依赖传统的位置差分来计算这些导数，而是通过卡尔曼增益实时、最优地融合模型预测与观测信息，实现对未测量状态（如速度、加速度）的动态估计。虽然在仅有位置传感器时，估计的性能（如收敛速度与精度）会有所下降，但这并不影响算法在理论上的完备性和工程上的实用性。

### 卡尔曼滤波中各项参数如何调整？

### 卡尔曼滤波与一般观测器的区别与联系

### 卡尔曼滤波与最小二乘法的区别与联系 

### 卡尔曼滤波的本质：加权平均

### 卡尔曼滤波的适用场合


## 估计误差协方差矩阵与卡尔曼增益矩阵不同形式的推导

$P_k$形式二：  

$$
\begin{aligned}
P_{k} & =\left(I-K_{k} H_{k}\right) P_{k-1}\left(I-K_{k} H_{k}\right)^{T}+K_{k} R_{k} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} H_{k} P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} R_{k} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k}\left(H_{k} P_{k-1} H_{k}^{T}+R_{k}\right) K_{k}^{T} \\
& \stackrel{(1)}{=} P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+K_{k} S_{k} K_{k}^{T} \\
& \stackrel{(2)}{=} P_{k-1}-K_{k} H_{k} P_{k-1}-P_{k-1} H_{k}^{T} K_{k}^{T}+P_{k-1} H_{k}^{T} K_{k}^{T} \\
& =P_{k-1}-K_{k} H_{k} P_{k-1} \\
& =\left(I-K_{k} H_{k}\right) P_{k-1}
\end{aligned}
$$

其中：  

$$
\begin{aligned}
\text{(1) } S_k &= H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } K_k &= P_{k-1} H_k^T S_k^{-1} \text{，得 } K_k S_k K_k^T = P_{k-1} H_k^T K_k^T
\end{aligned}
$$

$P_k$形式三： 

$$
\begin{aligned}
P_k &= (I - K_k H_k) P_{k-1} (I - K_k H_k)^T + K_k R_k K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k H_k P_{k-1} H_k^T K_k^T + K_k R_k K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k (H_k P_{k-1} H_k^T + R_k) K_k^T \\
&\stackrel{(1)}{=} P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + K_k S_k K_k^T \\
&\stackrel{(2)}{=} P_{k-1} - K_k H_k P_{k-1} - P_{k-1} H_k^T K_k^T + P_{k-1} H_k^T K_k^T \\
&= P_{k-1} - K_k H_k P_{k-1} \\
&= (I - K_k H_k) P_{k-1} \\
&\stackrel{(3)}{=} (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1}
\end{aligned}
$$

其中：  

$$
\begin{aligned}
\text{(1) } S_k = H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } K_k = P_{k-1} H_k^T S_k^{-1} \\
\text{(3) 由矩阵求逆引理:} (I - K_k H_k) P_{k-1} = (P_{k-1}^{-1} + H_k^T R_k^{-1} H_k)^{-1}
\end{aligned}
$$

$K_k$形式二：

$$
\begin{aligned}
K_k &= P_{k-1} H_k^T (H_k P_{k-1} H_k^T + R_k)^{-1} \\
&\stackrel{(1)}{=} P_{k-1} H_k^T S_k^{-1} \\
&\stackrel{(2)}{=} P_k (I - K_k H_k)^{-1} H_k^T S_k^{-1} \\
&\stackrel{(3)}{=} P_k H_k^T (I - H_k K_k)^{-1} S_k^{-1} \\
&\stackrel{(4)}{=} P_k H_k^T (I + H_k P_{k-1} H_k^T R_k^{-1})^{-1} S_k^{-1} \\
&\stackrel{(5)}{=} P_k H_k^T R_k^{-1}
\end{aligned}
$$

其中： 

$$
\begin{aligned}
\text{(1) } S_k &= H_k P_{k-1} H_k^T + R_k \\
\text{(2) 代入 } P_{k-1} &= (I - K_k H_k)^{-1} P_k \\
\text{(3) 利用 } (I - K_k H_k)^{-1} H_k^T &= H_k^T (I - H_k K_k)^{-1} \\
\text{(4) 代入 } K_k &= P_{k-1} H_k^T S_k^{-1} \text{，得 } H_k K_k = H_k P_{k-1} H_k^T S_k^{-1} \text{，故 } I - H_k K_k = (H_k P_{k-1} H_k^T + R_k)^{-1} R_k \text{，其逆为 } R_k^{-1} (H_k P_{k-1} H_k^T + R_k) \text{，代入化简} \\
\text{(5) 化简得 } P_k H_k^T R_k^{-1}
\end{aligned}
$$

## 参考   

最优状态估计:卡尔曼,H∞及非线性滤波(美)西蒙(Simon,D.)著;张勇刚,李宁,奔粤阳译.一北京:国防工业出版社,2013.5 ISBN 978-7-118-08808-3

阿波罗11号制导计算机中登月模块（Luminary099）原始代码的卡尔曼滤波部分：https://github.com/chrislgarry/Apollo-11/blob/master/Luminary099/KALMAN_FILTER.agc

网上相关资源  
